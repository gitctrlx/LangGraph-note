# å¿«é€Ÿå…¥é—¨

åœ¨è¿™ä¸ªç»¼åˆå¿«é€Ÿå…¥é—¨ä¸­ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªLangGraphæ”¯æŒçš„èŠå¤©æœºå™¨äººï¼Œå®ƒå¯ä»¥ï¼š

- é€šè¿‡**æœç´¢ç½‘ç»œ**å›ç­”å¸¸è§é—®é¢˜
- åœ¨å¤šæ¬¡è°ƒç”¨ä¹‹é—´**ä¿æŒå¯¹è¯çŠ¶æ€**
- å°†å¤æ‚æŸ¥è¯¢è·¯ç”±ç»™**äººç±»å®¡æ ¸**
- ä½¿ç”¨**è‡ªå®šä¹‰çŠ¶æ€æ¥æ§åˆ¶å…¶è¡Œä¸º**
- **å›æº¯å¹¶æ¢ç´¢æ›¿ä»£çš„å¯¹è¯è·¯å¾„**

æˆ‘ä»¬å°†ä»ä¸€ä¸ªåŸºæœ¬çš„èŠå¤©æœºå™¨äººå¼€å§‹ï¼Œå¹¶é€æ­¥å¢åŠ æ›´å¤æ‚çš„åŠŸèƒ½ï¼ŒåŒæ—¶ä»‹ç»LangGraphçš„å…³é”®æ¦‚å¿µã€‚

## è®¾ç½®

é¦–å…ˆï¼Œå®‰è£…æ‰€éœ€çš„åŒ…ï¼š

```py
pip install -U langgraph langsmith

# ç”¨äºæœ¬æ•™ç¨‹ï¼›ä¸æ˜¯LangGraphçš„å¿…è¦è¦æ±‚
pip install -U langchain_anthropic
```

æ¥ä¸‹æ¥ï¼Œè®¾ç½®æ‚¨çš„APIå¯†é’¥ï¼š

```py
import getpass
import os


def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")


_set_env("ANTHROPIC_API_KEY")
```

ï¼ˆæ¨èï¼‰[LangSmith](https://smith.langchain.com/) å¯ä»¥æ›´å®¹æ˜“åœ°çœ‹åˆ°â€œå¹•åâ€çš„è¿è¡Œæƒ…å†µã€‚

```py
_set_env("LANGSMITH_API_KEY")
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "LangGraph Tutorial"
```



## ç¬¬ä¸€éƒ¨åˆ†ï¼šæ„å»ºä¸€ä¸ªåŸºæœ¬çš„èŠå¤©æœºå™¨äºº

æˆ‘ä»¬å°†é¦–å…ˆä½¿ç”¨LangGraphåˆ›å»ºä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººã€‚è¿™ä¸ªèŠå¤©æœºå™¨äººå°†ç›´æ¥å“åº”ç”¨æˆ·æ¶ˆæ¯ã€‚å°½ç®¡ç®€å•ï¼Œä½†å®ƒå°†å±•ç¤ºä½¿ç”¨LangGraphæ„å»ºçš„æ ¸å¿ƒæ¦‚å¿µã€‚åœ¨æœ¬èŠ‚ç»“æŸæ—¶ï¼Œæ‚¨å°†æ„å»ºä¸€ä¸ªåŸºç¡€çš„èŠå¤©æœºå™¨äººã€‚



é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ª`StateGraph`ã€‚==`StateGraph`å¯¹è±¡å°†æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººçš„ç»“æ„å®šä¹‰ä¸ºâ€œçŠ¶æ€æœºâ€ã€‚æˆ‘ä»¬å°†æ·»åŠ `nodes`æ¥è¡¨ç¤ºèŠå¤©æœºå™¨äººå¯ä»¥è°ƒç”¨çš„llmå’Œå‡½æ•°ï¼Œå¹¶æ·»åŠ `edges`æ¥æŒ‡å®šæœºå™¨äººåœ¨è¿™äº›å‡½æ•°ä¹‹é—´çš„è½¬æ¢æ–¹å¼==ã€‚

```python
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

class State(TypedDict):
    # æ¶ˆæ¯çš„ç±»å‹ä¸ºâ€œlistâ€ã€‚æ³¨é‡Šä¸­çš„`add_messages`å‡½æ•°å®šä¹‰äº†è¯¥çŠ¶æ€é”®åº”å¦‚ä½•æ›´æ–°
    # ï¼ˆåœ¨æœ¬ä¾‹ä¸­ï¼Œå®ƒå°†æ¶ˆæ¯æ·»åŠ åˆ°åˆ—è¡¨ä¸­ï¼Œè€Œä¸æ˜¯è¦†ç›–å®ƒä»¬ï¼‰
    messages: Annotated[list, add_messages]
    # Annotated æ˜¯ä¸€ä¸ªç”¨æ¥é™„åŠ å…ƒæ•°æ®åˆ°ç±»å‹æ³¨è§£ä¸Šçš„å·¥å…·ã€‚å®ƒå…è®¸æˆ‘ä»¬åœ¨ç±»å‹æ³¨è§£ä¸­æ·»åŠ é¢å¤–çš„ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯ä¸ä¼šå½±å“ç±»å‹æ£€æŸ¥ï¼Œä½†æ˜¯å¯ä»¥åœ¨è¿è¡Œæ—¶ä½¿ç”¨ã€‚
    # Annotated[list, add_messages]è¡¨ç¤ºæ¶ˆæ¯çš„ç±»å‹æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå¹¶ä¸”é€šè¿‡æ³¨é‡Šadd_messagesæŒ‡å®šäº†å¦‚ä½•æ›´æ–°è¿™ä¸ªåˆ—è¡¨ã€‚

graph_builder = StateGraph(State)
```

**æ³¨æ„ï¼š** 

> å°† `State` å®šä¹‰ä¸ºä¸€ä¸ªå¸¦æœ‰å•ä¸ªé”® `messages` çš„ `TypedDict` æ„å‘³ç€æˆ‘ä»¬åœ¨å®šä¹‰ä¸€ä¸ªå­—å…¸ç±»å‹ï¼Œå…¶ä¸­è¿™ä¸ªå­—å…¸åªæœ‰ä¸€ä¸ªé”® `messages`ï¼Œå¹¶ä¸”è¿™ä¸ªé”®çš„å€¼æœ‰ç‰¹å®šçš„ç±»å‹å’Œè¡Œä¸ºã€‚
>
> æˆ‘ä»¬å°†`State`å®šä¹‰ä¸ºä¸€ä¸ªå¸¦æœ‰å•ä¸ªé”®`messages`çš„TypedDictã€‚`messages`é”®ç”¨[`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages)å‡½æ•°è¿›è¡Œæ³¨é‡Šï¼Œè¿™å‘Šè¯‰LangGraphå°†æ–°æ¶ˆæ¯æ·»åŠ åˆ°ç°æœ‰åˆ—è¡¨ä¸­ï¼Œè€Œä¸æ˜¯è¦†ç›–å®ƒä»¬ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬çš„å›¾çŸ¥é“ä¸¤ä»¶äº‹ï¼š

1. æˆ‘ä»¬å®šä¹‰çš„æ¯ä¸ª`node`å°†æ¥æ”¶å½“å‰çš„`State`ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ›´æ–°è¯¥çŠ¶æ€çš„å€¼ã€‚
2. `messages`å°†è¢«*æ·»åŠ *åˆ°å½“å‰åˆ—è¡¨ä¸­ï¼Œè€Œä¸æ˜¯ç›´æ¥è¦†ç›–ã€‚è¿™é€šè¿‡`Annotated`è¯­æ³•ä¸­çš„é¢„æ„å»ºå‡½æ•°[`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages)ä¼ è¾¾ã€‚



æ¥ä¸‹æ¥ï¼Œæ·»åŠ ä¸€ä¸ªâ€œ`chatbot`â€èŠ‚ç‚¹ï¼ˆnodeï¼‰ã€‚==èŠ‚ç‚¹ï¼ˆnodeï¼‰ä»£è¡¨å·¥ä½œå•å…ƒã€‚å®ƒä»¬é€šå¸¸æ˜¯å¸¸è§„çš„Pythonå‡½æ•°==ã€‚

```python
from langchain_anthropic import ChatAnthropic

llm = ChatAnthropic(model="claude-3-haiku-20240307")

def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}

	# è¿™ä¸ªå‡½æ•°æ¥æ”¶ä¸€ä¸ªStateä½œä¸ºè¾“å…¥ã€‚Stateæ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ä¸€ä¸ªé”®messagesï¼Œå…¶å€¼æ˜¯ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨ã€‚
	# llm.invoke(state["messages"])è°ƒç”¨è¯­è¨€æ¨¡å‹ï¼ˆllmï¼‰ç”Ÿæˆä¸€ä¸ªæ–°çš„æ¶ˆæ¯ã€‚
	# è¿”å›ä¸€ä¸ªæ–°çš„çŠ¶æ€å­—å…¸ï¼ŒåŒ…å«ä¸€ä¸ªæ›´æ–°çš„messagesåˆ—è¡¨ï¼Œå…¶ä¸­åªæœ‰æœ€æ–°ç”Ÿæˆçš„æ¶ˆæ¯ã€‚

# ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å”¯ä¸€çš„èŠ‚ç‚¹åç§°
# ç¬¬äºŒä¸ªå‚æ•°æ˜¯æ¯æ¬¡ä½¿ç”¨èŠ‚ç‚¹æ—¶å°†è°ƒç”¨çš„å‡½æ•°æˆ–å¯¹è±¡
graph_builder.add_node("chatbot", chatbot)
```

**æ³¨æ„ï¼š** 

> `chatbot`èŠ‚ç‚¹å‡½æ•°å¦‚ä½•å°†å½“å‰çš„`State`ä½œä¸ºè¾“å…¥å¹¶è¿”å›æ›´æ–°çš„`messages`åˆ—è¡¨ã€‚è¿™æ˜¯æ‰€æœ‰LangGraphèŠ‚ç‚¹å‡½æ•°çš„åŸºæœ¬æ¨¡å¼ã€‚

æˆ‘ä»¬`State`ä¸­çš„`add_messages`å‡½æ•°å°†llmçš„å“åº”æ¶ˆæ¯**æ·»åŠ **åˆ°çŠ¶æ€ä¸­å·²å­˜åœ¨çš„æ¶ˆæ¯ä¸­ã€‚



æ¥ä¸‹æ¥ï¼Œæ·»åŠ ä¸€ä¸ªâ€œå…¥å£â€ç‚¹ã€‚è¿™å‘Šè¯‰æˆ‘ä»¬çš„å›¾**æ¯æ¬¡è¿è¡Œæ—¶ä»å“ªé‡Œå¼€å§‹å·¥ä½œ**ã€‚

```python
graph_builder.add_edge(START, "chatbot")
```

åŒæ ·ï¼Œè®¾ç½®ä¸€ä¸ªâ€œç»“æŸâ€ç‚¹ã€‚è¿™æŒ‡ç¤ºå›¾å½¢**â€œæ¯æ¬¡è¿è¡Œæ­¤èŠ‚ç‚¹æ—¶ï¼Œæ‚¨å¯ä»¥é€€å‡ºã€‚â€**

```python
graph_builder.add_edge("chatbot", END)
```

æœ€åï¼Œæˆ‘ä»¬éœ€è¦èƒ½å¤Ÿè¿è¡Œæˆ‘ä»¬çš„å›¾ã€‚ä¸ºæ­¤ï¼Œè°ƒç”¨å›¾æ„å»ºå™¨ä¸Šçš„â€œ`compile()`â€ã€‚è¿™ä¼šåˆ›å»ºä¸€ä¸ªæˆ‘ä»¬å¯ä»¥åœ¨çŠ¶æ€ä¸Šè°ƒç”¨çš„â€œ`CompiledGraph`â€ã€‚

```python
graph = graph_builder.compile()
```

æ‚¨å¯ä»¥ä½¿ç”¨`get_graph`æ–¹æ³•å’Œä¸€ç§â€œdrawâ€æ–¹æ³•ï¼ˆå¦‚`draw_ascii`æˆ–`draw_png`ï¼‰æ¥å¯è§†åŒ–å›¾å½¢ã€‚`draw`æ–¹æ³•æ¯ä¸ªéƒ½éœ€è¦é¢å¤–çš„ä¾èµ–é¡¹ã€‚

```python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # è¿™éœ€è¦ä¸€äº›é¢å¤–çš„ä¾èµ–é¡¹ï¼Œæ˜¯å¯é€‰çš„
    pass
```

![image-20240708154630470](./assets/image-20240708154630470.png)



ç°åœ¨è®©æˆ‘ä»¬è¿è¡ŒèŠå¤©æœºå™¨äººï¼

**æç¤ºï¼š** æ‚¨å¯ä»¥éšæ—¶é€šè¿‡è¾“å…¥â€œquitâ€ã€â€œexitâ€æˆ–â€œqâ€é€€å‡ºèŠå¤©å¾ªç¯ã€‚

```python
while True:
    user_input = input("User: ")
    if user_input.lower() in ["quit", "exit", "q"]:
        print("Goodbye!")
        break
    for event in graph.stream({"messages": ("user", user_input)}):
        for value in event.values():
            print("Assistant:", value["messages"][-1].content)
            
    # graph.stream å‡½æ•°å°†ç”¨æˆ·è¾“å…¥ä¼ é€’ç»™å›¾ï¼Œå¹¶è¿”å›ä¸€ä¸ªäº‹ä»¶æµã€‚{"messages": ("user", user_input)} è¡¨ç¤ºç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯ã€‚
	# å¯¹äºæ¯ä¸ªäº‹ä»¶ï¼ˆeventï¼‰ï¼Œæˆ‘ä»¬è¿­ä»£å…¶å€¼ï¼ˆevent.values()ï¼‰
	# æ‰“å°åŠ©æ‰‹ç”Ÿæˆçš„æœ€åä¸€æ¡æ¶ˆæ¯å†…å®¹ï¼ˆvalue["messages"][-1].contentï¼‰
```

```python
User:  what's langgraph all about?
Assistant: Langgraph is a new open-source deep learning framework that focuses on enabling efficient training and deployment of large language models. Some key things to know about Langgraph:

1. Efficient Training: Langgraph is designed to accelerate the training of large language models by leveraging advanced optimization techniques and parallelization strategies.

2. Modular Architecture: Langgraph has a modular architecture that allows for easy customization and extension of language models, making it flexible for a variety of NLP tasks.

3. Hardware Acceleration: The framework is optimized for both CPU and GPU hardware, allowing for efficient model deployment on a wide range of devices.

4. Scalability: Langgraph is designed to handle large-scale language models with billions of parameters, enabling the development of state-of-the-art NLP applications.

5. Open-Source: Langgraph is an open-source project, allowing developers and researchers to collaborate, contribute, and build upon the framework.

6. Performance: The goal of Langgraph is to provide superior performance and efficiency compared to existing deep learning frameworks, particularly for training and deploying large language models.

Overall, Langgraph is a promising new deep learning framework that aims to address the challenges of building and deploying advanced natural language processing models at scale. It is an active area of research and development, with the potential to drive further advancements in the field of language AI.
User:  hm that doesn't seem right...
Assistant: I'm sorry, I don't have enough context to determine what doesn't seem right. Could you please provide more details about what you're referring to? That would help me better understand and respond appropriately.
User:  q
Goodbye!
```

**æ­å–œï¼** æ‚¨å·²ç»ä½¿ç”¨LangGraphæ„å»ºäº†ç¬¬ä¸€ä¸ªèŠå¤©æœºå™¨äººã€‚è¿™ä¸ªæœºå™¨äººå¯ä»¥é€šè¿‡æ¥æ”¶ç”¨æˆ·è¾“å…¥å¹¶ä½¿ç”¨LLMç”Ÿæˆå“åº”æ¥è¿›è¡ŒåŸºæœ¬å¯¹è¯ã€‚æ‚¨å¯ä»¥åœ¨æä¾›çš„é“¾æ¥ä¸­æŸ¥çœ‹ä¸Šé¢è°ƒç”¨çš„[LangSmith Trace](https://smith.langchain.com/public/29ab0177-1177-4d25-9341-17ae7d94e0e0/r)ã€‚

ä½†æ˜¯ï¼Œæ‚¨å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼Œæœºå™¨äººçš„çŸ¥è¯†ä»…é™äºå…¶è®­ç»ƒæ•°æ®ã€‚åœ¨ä¸‹ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†æ·»åŠ ä¸€ä¸ªç½‘ç»œæœç´¢å·¥å…·ï¼Œä»¥æ‰©å±•æœºå™¨äººçš„çŸ¥è¯†å¹¶ä½¿å…¶æ›´æœ‰èƒ½åŠ›ã€‚

ä¸‹é¢æ˜¯æœ¬èŠ‚çš„å®Œæ•´ä»£ç ä¾›æ‚¨å‚è€ƒï¼š

**å®Œæ•´ä»£ç **

```python
from typing import Annotated
from langchain_anthropic import ChatAnthropic
from typing_extensions import TypedDict
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages

class State(TypedDict):
    messages: Annotated[list, add_messages]

graph_builder = StateGraph(State)

llm = ChatAnthropic(model="claude-3-haiku-20240307")

def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}

# ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å”¯ä¸€çš„èŠ‚ç‚¹åç§°
# ç¬¬äºŒä¸ªå‚æ•°æ˜¯æ¯æ¬¡ä½¿ç”¨èŠ‚ç‚¹æ—¶å°†è°ƒç”¨çš„å‡½æ•°æˆ–å¯¹è±¡
graph_builder.add_node("chatbot", chatbot)
graph_builder.set_entry_point("chatbot")
graph_builder.set_finish_point("chatbot")
graph = graph_builder.compile()
```



## ç¬¬äºŒéƒ¨åˆ†ï¼šå¢å¼ºèŠå¤©æœºå™¨äººå·¥å…·

ä¸ºäº†å¤„ç†æˆ‘ä»¬èŠå¤©æœºå™¨äººæ— æ³•â€œä»è®°å¿†ä¸­â€å›ç­”çš„æŸ¥è¯¢ï¼Œæˆ‘ä»¬å°†é›†æˆä¸€ä¸ªç½‘ç»œæœç´¢å·¥å…·ã€‚æˆ‘ä»¬çš„æœºå™¨äººå¯ä»¥ä½¿ç”¨è¿™ä¸ªå·¥å…·æ¥æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯å¹¶æä¾›æ›´å¥½çš„å“åº”ã€‚

**è¦æ±‚**

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…å¿…è¦çš„è½¯ä»¶åŒ…å¹¶è®¾ç½®äº†APIå¯†é’¥ï¼š

é¦–å…ˆï¼Œå®‰è£…ä½¿ç”¨[Tavilyæœç´¢å¼•æ“](https://python.langchain.com/v0.2/docs/integrations/tools/tavily_search/)çš„å¿…éœ€ç»„ä»¶ï¼Œå¹¶è®¾ç½®æ‚¨çš„[TAVILY_API_KEY](https://tavily.com/)ã€‚

```python
pip install -U tavily-python
pip install -U langchain_community
```

```python
_set_env("TAVILY_API_KEY")
```

æ¥ä¸‹æ¥ï¼Œå®šä¹‰å·¥å…·ï¼š

```python
from langchain_community.tools.tavily_search import TavilySearchResults

tool = TavilySearchResults(max_results=2)
tools = [tool]
tool.invoke("What's a 'node' in LangGraph?")
```

è¾“å‡ºç»“æœï¼š

```python
[{'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',
  'content': 'Nodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making ...'},
 {'url': 'https://js.langchain.com/docs/langgraph',
  'content': "Assuming you have done the above Quick Start, you can build off it like:\nHere, we manually define the first tool call that we will make.\nNotice that it does that same thing as agent would have done (adds the agentOutcome key).\n LangGraph\nğŸ¦œğŸ•¸ï¸LangGraph.js\nâš¡ Building language agents as graphs âš¡\nOverview\u200b\nLangGraph is a library for building stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain.js.\n Therefore, we will use an object with one key (messages) with the value as an object: { value: Function, default?: () => any }\nThe default key must be a factory that returns the default value for that attribute.\n Streaming Node Output\u200b\nOne of the benefits of using LangGraph is that it is easy to stream output as it's produced by each node.\n What this means is that only one of the downstream edges will be taken, and which one that is depends on the results of the start node.\n"}]
```

ç»“æœæ˜¯é¡µé¢æ‘˜è¦ï¼Œæˆ‘ä»¬çš„èŠå¤©æœºå™¨äººå¯ä»¥ç”¨æ¥å›ç­”é—®é¢˜ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å¼€å§‹å®šä¹‰æˆ‘ä»¬çš„å›¾ã€‚ä»¥ä¸‹æ‰€æœ‰å†…å®¹ä¸ç¬¬ä¸€éƒ¨åˆ†ç›¸åŒï¼Œåªæ˜¯æˆ‘ä»¬åœ¨LLMä¸Šæ·»åŠ äº†`bind_tools`ã€‚è¿™ä½¿å¾—LLMçŸ¥é“å¦‚æœå®ƒæƒ³ä½¿ç”¨æˆ‘ä»¬çš„æœç´¢å¼•æ“ï¼Œè¯¥ä½¿ç”¨ä»€ä¹ˆæ ·çš„JSONæ ¼å¼ã€‚

```python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


llm = ChatAnthropic(model="claude-3-haiku-20240307")
# ä¿®æ”¹ï¼šå‘Šè¯‰LLMå®ƒå¯ä»¥è°ƒç”¨å“ªäº›å·¥å…·
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªå®é™…è¿è¡Œå·¥å…·çš„å‡½æ•°ã€‚å¦‚æœè°ƒç”¨äº†å·¥å…·ï¼Œæˆ‘ä»¬å°†é€šè¿‡å°†å·¥å…·æ·»åŠ åˆ°æ–°èŠ‚ç‚¹æ¥å®ç°è¿™ä¸€ç‚¹ã€‚

ä¸‹é¢ï¼Œå®æ–½ä¸€ä¸ª`BasicToolNode`ï¼Œæ£€æŸ¥çŠ¶æ€ä¸­çš„æœ€æ–°æ¶ˆæ¯ï¼Œå¹¶åœ¨æ¶ˆæ¯åŒ…å«`tool_calls`æ—¶è°ƒç”¨å·¥å…·ã€‚å®ƒä¾èµ–äºLLMçš„`tool_calling`æ”¯æŒï¼Œè¯¥æ”¯æŒåœ¨Anthropicã€OpenAIã€Google Geminiå’Œè®¸å¤šå…¶ä»–LLMæä¾›å•†ä¸­å¯ç”¨ã€‚

æˆ‘ä»¬ç¨åå°†ç”¨LangGraphçš„é¢„æ„å»º[ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode)æ¥æ›¿æ¢å®ƒï¼Œä»¥åŠ å¿«é€Ÿåº¦ï¼Œä½†é¦–å…ˆè‡ªå·±æ„å»ºå®ƒæ˜¯å¾ˆæœ‰å¯å‘æ€§çš„ã€‚

```python
import json
from langchain_core.messages import ToolMessage

class BasicToolNode:
    """è¿è¡Œæœ€åä¸€ä¸ªAIæ¶ˆæ¯ä¸­è¯·æ±‚çš„å·¥å…·çš„èŠ‚ç‚¹ã€‚"""

    def __init__(self, tools: list) -> None:
        self.tools_by_name = {tool.name: tool for tool in tools}

    def __call__(self, inputs: dict):
        if messages := inputs.get("messages", []):
            message = messages[-1]
        else:
            raise ValueError("è¾“å…¥ä¸­æ‰¾ä¸åˆ°æ¶ˆæ¯")
        outputs = []
        for tool_call in message.tool_calls:
            tool_result = self.tools_by_name[tool_call["name"]].invoke(
                tool_call["args"]
            )
            outputs.append(
                ToolMessage(
                    content=json.dumps(tool_result),
                    name=tool_call["name"],
                    tool_call_id=tool_call["id"],
                )
            )
        return {"messages": outputs}

tool_node = BasicToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)
```

æ·»åŠ å·¥å…·èŠ‚ç‚¹åï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰`conditional_edges`ã€‚

å›æƒ³ä¸€ä¸‹ï¼Œ**edges**å°†æ§åˆ¶æµä»ä¸€ä¸ªèŠ‚ç‚¹è·¯ç”±åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚**Conditional edges**é€šå¸¸åŒ…å«â€œifâ€è¯­å¥ï¼Œä»¥æ ¹æ®å½“å‰å›¾å½¢çŠ¶æ€è·¯ç”±åˆ°ä¸åŒçš„èŠ‚ç‚¹ã€‚è¿™äº›å‡½æ•°æ¥æ”¶å½“å‰çš„å›¾å½¢`state`å¹¶è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨ï¼ŒæŒ‡ç¤ºæ¥ä¸‹æ¥è°ƒç”¨å“ªä¸ªèŠ‚ç‚¹ã€‚

ä¸‹é¢ï¼Œå®šä¹‰ä¸€ä¸ªåä¸º`route_tools`çš„è·¯ç”±å‡½æ•°ï¼Œæ£€æŸ¥èŠå¤©æœºå™¨äººçš„è¾“å‡ºä¸­æ˜¯å¦æœ‰tool_callsã€‚é€šè¿‡è°ƒç”¨`add_conditional_edges`å°†æ­¤å‡½æ•°æä¾›ç»™å›¾å½¢ï¼Œè¿™å‘Šè¯‰å›¾å½¢æ¯å½“`chatbot`èŠ‚ç‚¹å®Œæˆæ—¶æ£€æŸ¥æ­¤å‡½æ•°ä»¥æŸ¥çœ‹æ¥ä¸‹æ¥è¯¥å»å“ªé‡Œã€‚

è¯¥æ¡ä»¶å°†è·¯ç”±åˆ°`tools`ï¼Œå¦‚æœå­˜åœ¨å·¥å…·è°ƒç”¨ï¼Œåˆ™è·¯ç”±åˆ°"`__end__`"ã€‚

ç¨åï¼Œæˆ‘ä»¬å°†ç”¨é¢„æ„å»ºçš„[tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition)æ›¿æ¢å®ƒï¼Œä»¥ä½¿å…¶æ›´åŠ ç®€æ´ï¼Œä½†é¦–å…ˆè‡ªå·±å®ç°å®ƒä¼šæ›´åŠ æ¸…æ™°ã€‚

```python
from typing import Literal

def route_tools(
    state: State,
) -> Literal["tools", "__end__"]:
    """
    åœ¨conditional_edgeä¸­ä½¿ç”¨ï¼Œå¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æœ‰å·¥å…·è°ƒç”¨ï¼Œåˆ™è·¯ç”±åˆ°ToolNodeã€‚
    å¦åˆ™ï¼Œè·¯ç”±åˆ°ç»“æŸã€‚
    """
    if isinstance(state, list):
        ai_message = state[-1]
    elif messages := state.get("messages", []):
        ai_message = messages[-1]
    else:
        raise ValueError(f"è¾“å…¥çŠ¶æ€ä¸­æ‰¾ä¸åˆ°æ¶ˆæ¯ï¼š{state}")
    if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
        return "tools"
    return "__end__"

# `tools_condition`å‡½æ•°åœ¨èŠå¤©æœºå™¨äººè¯·æ±‚ä½¿ç”¨å·¥å…·æ—¶è¿”å›â€œtoolsâ€ï¼Œåœ¨ç›´æ¥å“åº”æ—¶è¿”å›â€œ__end__â€ã€‚
# è¿™ç§æ¡ä»¶è·¯ç”±å®šä¹‰äº†ä¸»ä»£ç†å¾ªç¯ã€‚
graph_builder.add_conditional_edges(
    "chatbot",
    route_tools,
    {"tools": "tools", "__end__": "__end__"},
)
# æ¯æ¬¡è°ƒç”¨å·¥å…·æ—¶ï¼Œæˆ‘ä»¬è¿”å›åˆ°èŠå¤©æœºå™¨äººä»¥å†³å®šä¸‹ä¸€æ­¥
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
graph = graph_builder.compile()
```

**æ³¨æ„ï¼š** 

> æ¡ä»¶è¾¹ä»å•ä¸ªèŠ‚ç‚¹å¼€å§‹ã€‚è¿™å‘Šè¯‰å›¾å½¢â€œæ¯æ¬¡è¿è¡Œ`chatbot`èŠ‚ç‚¹æ—¶ï¼Œå¦‚æœè°ƒç”¨å·¥å…·ï¼Œåˆ™è½¬åˆ°`tools`ï¼Œå¦åˆ™ç»“æŸå¾ªç¯ã€‚â€

å°±åƒé¢„æ„å»ºçš„`tools_condition`ä¸€æ ·ï¼Œæˆ‘ä»¬çš„å‡½æ•°å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œåˆ™è¿”å›"`__end__`"å­—ç¬¦ä¸²ã€‚å½“å›¾å½¢è¿‡æ¸¡åˆ°`__end__`æ—¶ï¼Œå®ƒæ²¡æœ‰æ›´å¤šçš„ä»»åŠ¡è¦å®Œæˆå¹¶åœæ­¢æ‰§è¡Œã€‚å› ä¸ºæ¡ä»¶å¯ä»¥è¿”å›`__end__`ï¼Œæ‰€ä»¥è¿™æ¬¡æˆ‘ä»¬ä¸éœ€è¦æ˜¾å¼è®¾ç½®ä¸€ä¸ª`finish_point`ã€‚æˆ‘ä»¬çš„å›¾å½¢å·²ç»æœ‰äº†ç»“æŸçš„æ–¹æ³•ï¼

è®©æˆ‘ä»¬å¯è§†åŒ–æˆ‘ä»¬æ„å»ºçš„å›¾å½¢ã€‚ä»¥ä¸‹åŠŸèƒ½éœ€è¦ä¸€äº›é¢å¤–çš„ä¾èµ–é¡¹æ¥è¿è¡Œï¼Œè¿™å¯¹äºæœ¬æ•™ç¨‹å¹¶ä¸é‡è¦ã€‚

```python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # è¿™éœ€è¦ä¸€äº›é¢å¤–çš„ä¾èµ–é¡¹ï¼Œæ˜¯å¯é€‰çš„
    pass
```

![No description has been provided for this image](data:image/jpeg;base64,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)

ç°åœ¨æˆ‘ä»¬å¯ä»¥é—®æœºå™¨äººå…¶è®­ç»ƒæ•°æ®ä¹‹å¤–çš„é—®é¢˜ã€‚

```python
from langchain_core.messages import BaseMessage

while True:
    user_input = input("User: ")
    if user_input.lower() in ["quit", "exit", "q"]:
        print("Goodbye!")
        break
    for event in graph.stream({"messages": [("user", user_input)]}):
        for value in event.values():
            if isinstance(value["messages"][-1], BaseMessage):
                print("Assistant:", value["messages"][-1].content)
```

```python
User:  what's langgraph all about?
Assistant: [{'id': 'toolu_01L1TABSBXsHPsebWiMPNqf1', 'input': {'query': 'langgraph'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]
Assistant: [{"url": "https://langchain-ai.github.io/langgraph/", "content": "LangGraph is framework agnostic (each node is a regular python function). It extends the core Runnable API (shared interface for streaming, async, and batch calls) to make it easy to: Seamless state management across multiple turns of conversation or tool usage. The ability to flexibly route between nodes based on dynamic criteria."}, {"url": "https://blog.langchain.dev/langgraph-multi-agent-workflows/", "content": "As a part of the launch, we highlighted two simple runtimes: one that is the equivalent of the AgentExecutor in langchain, and a second that was a version of that aimed at message passing and chat models.\n It's important to note that these three examples are only a few of the possible examples we could highlight - there are almost assuredly other examples out there and we look forward to seeing what the community comes up with!\n LangGraph: Multi-Agent Workflows\nLinks\nLast week we highlighted LangGraph - a new package (available in both Python and JS) to better enable creation of LLM workflows containing cycles, which are a critical component of most agent runtimes. \"\nAnother key difference between Autogen and LangGraph is that LangGraph is fully integrated into the LangChain ecosystem, meaning you take fully advantage of all the LangChain integrations and LangSmith observability.\n As part of this launch, we're also excited to highlight a few applications built on top of LangGraph that utilize the concept of multiple agents.\n"}]
Assistant: æ ¹æ®æœç´¢ç»“æœï¼ŒLangGraphæ˜¯ä¸€ä¸ªä¸æ¡†æ¶æ— å…³çš„Pythonå’ŒJavaScriptåº“ï¼Œå®ƒæ‰©å±•äº†LangChainé¡¹ç›®çš„æ ¸å¿ƒRunnable APIï¼Œä»¥æ”¯æŒåˆ›å»ºæ¶‰åŠå¤šä¸ªä»£ç†æˆ–ç»„ä»¶çš„æ›´å¤æ‚çš„å·¥ä½œæµã€‚å…³äºLangGraphçš„ä¸€äº›å…³é”®ç‚¹ï¼š

- å®ƒä½¿å¾—åœ¨å¤šè½®å¯¹è¯æˆ–å·¥å…·ä½¿ç”¨ä¸­æ— ç¼ç®¡ç†çŠ¶æ€å˜å¾—æ›´åŠ å®¹æ˜“ï¼Œå¹¶ä¸”å¯ä»¥æ ¹æ®åŠ¨æ€æ¡ä»¶åœ¨ä¸åŒèŠ‚ç‚¹/ç»„ä»¶ä¹‹é—´çµæ´»è·¯ç”±ã€‚

- å®ƒä¸LangChainç”Ÿæ€ç³»ç»Ÿé›†æˆï¼Œå…è®¸æ‚¨åˆ©ç”¨LangChainçš„é›†æˆå’Œå¯è§‚æµ‹æ€§åŠŸèƒ½ã€‚

- å®ƒæ”¯æŒåˆ›å»ºå¤šä»£ç†å·¥ä½œæµï¼Œå…¶ä¸­ä¸åŒçš„ç»„ä»¶æˆ–ä»£ç†å¯ä»¥æ¯”æ ‡å‡†çš„LangChain AgentExecutoræ›´çµæ´»ã€æ›´å¤æ‚åœ°ä¸²è”åœ¨ä¸€èµ·ã€‚

- æ ¸å¿ƒæ€æƒ³æ˜¯æä¾›ä¸€ä¸ªæ›´å¼ºå¤§ã€æ›´çµæ´»çš„æ¡†æ¶ï¼Œç”¨äºæ„å»ºç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åº”ç”¨ç¨‹åºå’Œå·¥ä½œæµï¼Œè¶…è¶Šä»…ä½¿ç”¨æ ¸å¿ƒLangChainå·¥å…·çš„å¯èƒ½æ€§ã€‚

æ€»ä½“è€Œè¨€ï¼ŒLangGraphä¼¼ä¹æ˜¯LangChainå·¥å…·åŒ…çš„ä¸€ä¸ªæœ‰ç”¨è¡¥å……ï¼Œé‡ç‚¹æ˜¯æ”¯æŒç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ›´é«˜çº§çš„å¤šä»£ç†æ ·å¼çš„åº”ç”¨ç¨‹åºå’Œå·¥ä½œæµã€‚
User:  neat!
Assistant: I'm afraid I don't have enough context to provide a substantive response to "neat!". As an AI assistant, I'm designed to have conversations and provide information to users, but I need more details or a specific question from you in order to give a helpful reply. Could you please rephrase your request or provide some additional context? I'd be happy to assist further once I understand what you're looking for.
User:  what?
Assistant: I'm afraid I don't have enough context to provide a meaningful response to "what?". Could you please rephrase your request or provide more details about what you are asking? I'd be happy to try to assist you further once I have a clearer understanding of your query.
User:  q
Goodbye!
```

**æ­å–œï¼** æ‚¨å·²ç»åœ¨LangGraphä¸­åˆ›å»ºäº†ä¸€ä¸ªå¯ä»¥ä½¿ç”¨æœç´¢å¼•æ“æ£€ç´¢æœ€æ–°ä¿¡æ¯çš„å¯¹è¯ä»£ç†ã€‚ç°åœ¨å®ƒå¯ä»¥å¤„ç†æ›´å¹¿æ³›çš„ç”¨æˆ·æŸ¥è¯¢ã€‚è¦æ£€æŸ¥æ‚¨çš„ä»£ç†åˆšåˆšæ‰§è¡Œçš„æ‰€æœ‰æ­¥éª¤ï¼Œè¯·æŸ¥çœ‹æ­¤[LangSmith trace](https://smith.langchain.com/public/24b94adc-3356-4d9f-8f94-813f8004fdbe/r)ã€‚

æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººä»ç„¶æ— æ³•è‡ªå·±è®°ä½è¿‡å»çš„äº’åŠ¨ï¼Œé™åˆ¶äº†å…¶è¿›è¡Œè¿è´¯çš„å¤šè½®å¯¹è¯çš„èƒ½åŠ›ã€‚åœ¨ä¸‹ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†æ·»åŠ **å†…å­˜**æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­åˆ›å»ºçš„å›¾å½¢çš„å®Œæ•´ä»£ç å¦‚ä¸‹ï¼Œæ›¿æ¢äº†æˆ‘ä»¬çš„`BasicToolNode`ï¼Œç”¨é¢„æ„å»ºçš„[ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode)ï¼Œå¹¶ç”¨é¢„æ„å»ºçš„[tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition)æ›¿æ¢äº†æˆ‘ä»¬çš„`route_tools`æ¡ä»¶ã€‚

**å®Œæ•´ä»£ç ï¼š**

```python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-haiku-20240307")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
# æ¯æ¬¡è°ƒç”¨å·¥å…·æ—¶ï¼Œæˆ‘ä»¬è¿”å›åˆ°èŠå¤©æœºå™¨äººä»¥å†³å®šä¸‹ä¸€æ­¥
graph_builder.add_edge("tools", "chatbot")
graph_builder.set_entry_point("chatbot")
graph = graph_builder.compile()
```

**PSï¼šç›®å‰æ”¯æŒè°ƒç”¨toolsçš„æ¥å£**

æˆªè‡³ 2024-07-08ï¼Œå‚è€ƒï¼šhttps://python.langchain.com/v0.2/docs/integrations/chat/

> [ChatOpenAI ](https://python.langchain.com/v0.2/docs/integrations/chat/openai/)æ˜¯æ¥è‡ª`langchain_openai`åŒ…ä¸­çš„ï¼Œè€Œä¸æ˜¯`langchain_community.chat_models`ä¸­çš„ã€‚

| Model                                                        | [Tool calling](https://python.langchain.com/v0.2/docs/how_to/tool_calling/) | [Structured output](https://python.langchain.com/v0.2/docs/how_to/structured_output/) | JSON mode | Local | [Multimodal](https://python.langchain.com/v0.2/docs/how_to/multimodal_inputs/) | Package                   |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- | ----- | ------------------------------------------------------------ | ------------------------- |
| [AzureChatOpenAI](https://python.langchain.com/v0.2/docs/integrations/chat/azure_chat_openai/) | âœ…                                                            | âœ…                                                            | âœ…         | âŒ     | âœ…                                                            | langchain-openai          |
| [ChatAnthropic](https://python.langchain.com/v0.2/docs/integrations/chat/anthropic/) | âœ…                                                            | âœ…                                                            | âŒ         | âŒ     | âœ…                                                            | langchain-anthropic       |
| [ChatBedrock](https://python.langchain.com/v0.2/docs/integrations/chat/bedrock/) | âœ…                                                            | âœ…                                                            | âŒ         | âŒ     | âŒ                                                            | langchain-aws             |
| [ChatCohere](https://python.langchain.com/v0.2/docs/integrations/chat/cohere/) | âœ…                                                            | âœ…                                                            | âŒ         | âŒ     | âŒ                                                            | langchain-cohere          |
| [ChatEdenAI](https://python.langchain.com/v0.2/docs/integrations/chat/edenai/) | âœ…                                                            | âœ…                                                            | âŒ         | âŒ     | âŒ                                                            | langchain-community       |
| [ChatFireworks](https://python.langchain.com/v0.2/docs/integrations/chat/fireworks/) | âœ…                                                            | âœ…                                                            | âœ…         | âŒ     | âŒ                                                            | langchain-fireworks       |
| [ChatGoogleGenerativeAI](https://python.langchain.com/v0.2/docs/integrations/chat/google_generative_ai/) | âœ…                                                            | âœ…                                                            | âŒ         | âŒ     | âœ…                                                            | langchain-google-genai    |
| [ChatGroq](https://python.langchain.com/v0.2/docs/integrations/chat/groq/) | âœ…                                                            | âœ…                                                            | âœ…         | âŒ     | âŒ                                                            | langchain-groq            |
| [ChatHuggingFace](https://python.langchain.com/v0.2/docs/integrations/chat/huggingface/) | âœ…                                                            | âœ…                                                            | âŒ         | âœ…     | âŒ                                                            | langchain-huggingface     |
| [ChatLlamaCpp](https://python.langchain.com/v0.2/docs/integrations/chat/llamacpp/) | âœ…                                                            | âœ…                                                            | âŒ         | âœ…     | âŒ                                                            | langchain-community       |
| [ChatMistralAI](https://python.langchain.com/v0.2/docs/integrations/chat/mistralai/) | âœ…                                                            | âœ…                                                            | âŒ         | âŒ     | âŒ                                                            | langchain-mistralai       |
| [ChatOllama](https://python.langchain.com/v0.2/docs/integrations/chat/ollama/) | âŒ                                                            | âŒ                                                            | âœ…         | âœ…     | âŒ                                                            | langchain-community       |
| [ChatOpenAI](https://python.langchain.com/v0.2/docs/integrations/chat/openai/) | âœ…                                                            | âœ…                                                            | âœ…         | âŒ     | âœ…                                                            | langchain-openai          |
| [ChatTogether](https://python.langchain.com/v0.2/docs/integrations/chat/together/) | âœ…                                                            | âœ…                                                            | âœ…         | âŒ     | âŒ                                                            | langchain-together        |
| [ChatVertexAI](https://python.langchain.com/v0.2/docs/integrations/chat/google_vertex_ai_palm/) | âœ…                                                            | âœ…                                                            | âŒ         | âŒ     | âœ…                                                            | langchain-google-vertexai |
| [vLLM Chat (via ChatOpenAI)](https://python.langchain.com/v0.2/docs/integrations/chat/vllm/) | âŒ                                                            | âŒ                                                            | âŒ         | âœ…     | âŒ                                                            | langchain-openai          |



## ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¸ºèŠå¤©æœºå™¨äººæ·»åŠ è®°å¿†åŠŸèƒ½

æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººç°åœ¨å¯ä»¥ä½¿ç”¨å·¥å…·å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œä½†å®ƒä¸è®°å¾—ä¹‹å‰äº’åŠ¨çš„ä¸Šä¸‹æ–‡ã€‚è¿™é™åˆ¶äº†å®ƒè¿›è¡Œè¿è´¯å¤šè½®å¯¹è¯çš„èƒ½åŠ›ã€‚

LangGraphé€šè¿‡**æŒä¹…æ£€æŸ¥ç‚¹**è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚å¦‚æœåœ¨ç¼–è¯‘å›¾å½¢æ—¶æä¾›`checkpointer`ï¼Œå¹¶åœ¨è°ƒç”¨å›¾å½¢æ—¶æä¾›`thread_id`ï¼ŒLangGraphä¼šåœ¨æ¯ä¸€æ­¥åè‡ªåŠ¨ä¿å­˜çŠ¶æ€ã€‚å½“æ‚¨ä½¿ç”¨ç›¸åŒçš„`thread_id`å†æ¬¡è°ƒç”¨å›¾å½¢æ—¶ï¼Œå›¾å½¢ä¼šåŠ è½½å…¶ä¿å­˜çš„çŠ¶æ€ï¼Œä½¿èŠå¤©æœºå™¨äººèƒ½å¤Ÿä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­ã€‚

æˆ‘ä»¬ç¨åä¼šçœ‹åˆ°ï¼Œ**æ£€æŸ¥ç‚¹**æ¯”ç®€å•çš„èŠå¤©è®°å¿†åŠŸèƒ½æ›´å¼ºå¤§â€”â€”å®ƒå…è®¸æ‚¨éšæ—¶ä¿å­˜å’Œæ¢å¤å¤æ‚çš„çŠ¶æ€ï¼Œç”¨äºé”™è¯¯æ¢å¤ã€äººç±»å‚ä¸çš„å·¥ä½œæµã€æ—¶å…‰æ—…è¡Œäº¤äº’ç­‰ã€‚ä½†æ˜¯åœ¨æˆ‘ä»¬æ·±å…¥è®¨è®ºä¹‹å‰ï¼Œè®©æˆ‘ä»¬é€šè¿‡æ·»åŠ æ£€æŸ¥ç‚¹æ¥å®ç°å¤šè½®å¯¹è¯ã€‚

é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ª`SqliteSaver`æ£€æŸ¥ç‚¹ã€‚

```python
from langgraph.checkpoint.sqlite import SqliteSaver

memory = SqliteSaver.from_conn_string(":memory:")
```

**æ³¨æ„** æˆ‘ä»¬å°†`:memory`æŒ‡å®šä¸ºSqliteæ•°æ®åº“è·¯å¾„ã€‚è¿™å¯¹äºæˆ‘ä»¬çš„æ•™ç¨‹æ¥è¯´å¾ˆæ–¹ä¾¿ï¼ˆå®ƒå°†æ‰€æœ‰æ•°æ®ä¿å­˜åœ¨å†…å­˜ä¸­ï¼‰ã€‚åœ¨ç”Ÿäº§åº”ç”¨ç¨‹åºä¸­ï¼Œæ‚¨å¯èƒ½ä¼šæ›´æ”¹æ­¤è®¾ç½®ä»¥è¿æ¥åˆ°æ‚¨è‡ªå·±çš„æ•°æ®åº“å’Œ/æˆ–ä½¿ç”¨å…¶ä»–æ£€æŸ¥ç‚¹ç±»ã€‚

æ¥ä¸‹æ¥å®šä¹‰å›¾å½¢ã€‚æ—¢ç„¶æ‚¨å·²ç»æ„å»ºäº†è‡ªå·±çš„`BasicToolNode`ï¼Œæˆ‘ä»¬å°†ç”¨LangGraphçš„é¢„æ„å»º`ToolNode`å’Œ`tools_condition`æ›¿æ¢å®ƒä»¬ï¼Œå› ä¸ºè¿™äº›å¯ä»¥è¿›è¡Œå¹¶è¡ŒAPIæ‰§è¡Œã€‚é™¤æ­¤ä¹‹å¤–ï¼Œä»¥ä¸‹å†…å®¹å‡ä»ç¬¬äºŒéƒ¨åˆ†å¤åˆ¶ã€‚

```python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-haiku-20240307")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
# æ¯æ¬¡è°ƒç”¨å·¥å…·æ—¶ï¼Œæˆ‘ä»¬è¿”å›åˆ°èŠå¤©æœºå™¨äººä»¥å†³å®šä¸‹ä¸€æ­¥
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
```

```python
/Users/wfh/code/lc/langchain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The method `ChatAnthropic.bind_tools` is in beta. It is actively being worked on, so the API may change.
  warn_beta(
```

æœ€åï¼Œç”¨æä¾›çš„æ£€æŸ¥ç‚¹ç¼–è¯‘å›¾å½¢ã€‚

```python
graph = graph_builder.compile(checkpointer=memory)
```

è¯·æ³¨æ„ï¼Œä»ç¬¬äºŒéƒ¨åˆ†å¼€å§‹ï¼Œå›¾å½¢çš„è¿æ¥æ€§æ²¡æœ‰æ”¹å˜ã€‚æˆ‘ä»¬æ‰€åšçš„ä¸€åˆ‡éƒ½æ˜¯åœ¨å›¾å½¢å¤„ç†æ¯ä¸ªèŠ‚ç‚¹æ—¶æ£€æŸ¥`State`ã€‚

```python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # è¿™éœ€è¦ä¸€äº›é¢å¤–çš„ä¾èµ–é¡¹ï¼Œæ˜¯å¯é€‰çš„
    pass
```

![No description has been provided for this image](data:image/jpeg;base64,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)

ç°åœ¨æ‚¨å¯ä»¥ä¸æ‚¨çš„æœºå™¨äººäº’åŠ¨äº†ï¼é¦–å…ˆï¼Œé€‰æ‹©ä¸€ä¸ªçº¿ç¨‹ä½œä¸ºæœ¬æ¬¡å¯¹è¯çš„é”®ã€‚

```python
config = {"configurable": {"thread_id": "1"}}
```

æ¥ä¸‹æ¥ï¼Œè°ƒç”¨æ‚¨çš„èŠå¤©æœºå™¨äººã€‚

```python
user_input = "Hi there! My name is Will."

# configæ˜¯stream()æˆ–invoke()çš„**ç¬¬äºŒä¸ªä½ç½®å‚æ•°**ï¼
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    event["messages"][-1].pretty_print()
```

```python
================================ Human Message =================================

Hi there! My name is Will.
================================== Ai Message ==================================

It's nice to meet you, Will! I'm an AI assistant created by Anthropic. I'm here to help you with any questions or tasks you may have. Please let me know how I can assist you today.
```

**æ³¨æ„ï¼š** åœ¨è°ƒç”¨å›¾å½¢æ—¶ï¼Œconfigä½œä¸º**ç¬¬äºŒä¸ªä½ç½®å‚æ•°**æä¾›ã€‚é‡è¦çš„æ˜¯ï¼Œå®ƒ**æ²¡æœ‰**åµŒå¥—åœ¨å›¾å½¢è¾“å…¥ä¸­ï¼ˆ`{'messages': []}`ï¼‰ã€‚

è®©æˆ‘ä»¬é—®ä¸€ä¸ªè·Ÿè¿›é—®é¢˜ï¼šçœ‹çœ‹å®ƒæ˜¯å¦è®°å¾—æ‚¨çš„åå­—ã€‚

```python
user_input = "Remember my name?"

# configæ˜¯stream()æˆ–invoke()çš„**ç¬¬äºŒä¸ªä½ç½®å‚æ•°**ï¼
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    event["messages"][-1].pretty_print()
```

```python
================================ Human Message =================================

Remember my name?
================================== Ai Message ==================================

Of course, your name is Will. It's nice to meet you again!
```

**æ³¨æ„** æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨å¤–éƒ¨åˆ—è¡¨æ¥å­˜å‚¨è®°å¿†ï¼šä¸€åˆ‡éƒ½ç”±æ£€æŸ¥ç‚¹å¤„ç†ï¼æ‚¨å¯ä»¥åœ¨è¿™ä¸ª[LangSmith trace](https://smith.langchain.com/public/48387889-c002-47a8-9f6a-1f6b298db64b/r)ä¸­æ£€æŸ¥å®Œæ•´çš„æ‰§è¡Œæƒ…å†µã€‚

ä¸ä¿¡ï¼Ÿè¯•è¯•ä½¿ç”¨ä¸åŒçš„é…ç½®ã€‚

```python
# å”¯ä¸€çš„åŒºåˆ«æ˜¯æˆ‘ä»¬åœ¨è¿™é‡Œå°†`thread_id`æ”¹ä¸º"2"è€Œä¸æ˜¯"1"
events = graph.stream(
    {"messages": [("user", user_input)]},
    {"configurable": {"thread_id": "2"}},
    stream_mode="values",
)
for event in events:
    event["messages"][-1].pretty_print()
```

```python
================================ Human Message =================================

Remember my name?
================================== Ai Message ==================================

I'm afraid I don't actually have the capability to remember your name. As an AI assistant, I don't have a persistent memory of our previous conversations or interactions. I respond based on the current context provided to me. Could you please restate your name or provide more information so I can try to assist you?
```

**æ³¨æ„** æˆ‘ä»¬æ‰€åšçš„**å”¯ä¸€**æ›´æ”¹æ˜¯ä¿®æ”¹é…ç½®ä¸­çš„`thread_id`ã€‚è¯·å‚é˜…æ­¤è°ƒç”¨çš„[LangSmith trace](https://smith.langchain.com/public/4647adf6-3835-4ce3-ba39-26ed4f167411/r)è¿›è¡Œæ¯”è¾ƒã€‚

åˆ°ç°åœ¨ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»åœ¨ä¸¤ä¸ªä¸åŒçš„çº¿ç¨‹ä¸­åšäº†ä¸€äº›æ£€æŸ¥ç‚¹ã€‚ä½†æ˜¯ï¼Œæ£€æŸ¥ç‚¹ä¸­åŒ…å«äº†ä»€ä¹ˆï¼Ÿè¦éšæ—¶æ£€æŸ¥ç»™å®šé…ç½®çš„å›¾å½¢çš„`state`ï¼Œè¯·è°ƒç”¨`get_state(config)`ã€‚

```python
snapshot = graph.get_state(config)
snapshot
```

```python
StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Will.', id='aad97d7f-8845-4f9e-b723-2af3b7c97590'), AIMessage(content="It's nice to meet you, Will! I'm an AI assistant created by Anthropic. I'm here to help you with any questions or tasks you may have. Please let me know how I can assist you today.", response_metadata={'id': 'msg_01VCz7Y5jVmMZXibBtnECyvJ', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 375, 'output_tokens': 49}}, id='run-66cf1695-5ba8-4fd8-a79d-ded9ee3c3b33-0'), HumanMessage(content='Remember my name?', id='ac1e9971-dbee-4622-9e63-5015dee05c20'), AIMessage(content="Of course, your name is Will. It's nice to meet you again!", response_metadata={'id': 'msg_01RsJ6GaQth7r9soxbF7TSpQ', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 431, 'output_tokens': 19}}, id='run-890149d3-214f-44e8-9717-57ec4ef68224-0')]}, next=(), config={'configurable': {'thread_id': '1', 'thread_ts': '2024-05-06T22:23:20.430350+00:00'}}, parent_config=None)
```

```python
snapshot.next  # (ç”±äºå›¾å½¢åœ¨æœ¬è½®ç»“æŸï¼Œ`next`ä¸ºç©ºã€‚å¦‚æœæ‚¨åœ¨å›¾å½¢è°ƒç”¨æœŸé—´è·å–çŠ¶æ€ï¼Œnextä¼šå‘Šè¯‰æ‚¨æ¥ä¸‹æ¥å°†æ‰§è¡Œå“ªä¸ªèŠ‚ç‚¹)
```

```python
()
```

ä¸Šé¢çš„å¿«ç…§åŒ…å«äº†å½“å‰çŠ¶æ€å€¼ã€ç›¸åº”çš„é…ç½®å’Œè¦å¤„ç†çš„`next`èŠ‚ç‚¹ã€‚åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼Œå›¾å½¢å·²è¾¾åˆ°`__end__`çŠ¶æ€ï¼Œå› æ­¤`next`ä¸ºç©ºã€‚

**æ­å–œï¼** æ‚¨çš„èŠå¤©æœºå™¨äººç°åœ¨å¯ä»¥é€šè¿‡LangGraphçš„æ£€æŸ¥ç‚¹ç³»ç»Ÿåœ¨ä¼šè¯ä¹‹é—´ä¿æŒå¯¹è¯çŠ¶æ€ã€‚è¿™ä¸º

æ›´è‡ªç„¶ã€æ›´æœ‰ä¸Šä¸‹æ–‡çš„äº¤äº’å¼€è¾Ÿäº†ä»¤äººå…´å¥‹çš„å¯èƒ½æ€§ã€‚LangGraphçš„æ£€æŸ¥ç‚¹ç”šè‡³å¯ä»¥å¤„ç†**ä»»æ„å¤æ‚çš„å›¾å½¢çŠ¶æ€**ï¼Œè¿™æ¯”ç®€å•çš„èŠå¤©è®°å¿†åŠŸèƒ½æ›´å…·è¡¨ç°åŠ›å’Œå¼ºå¤§ã€‚

åœ¨ä¸‹ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†å¼•å…¥äººç±»ç›‘ç£åŠŸèƒ½ï¼Œä»¥å¤„ç†æœºå™¨äººåœ¨ç»§ç»­ä¹‹å‰å¯èƒ½éœ€è¦æŒ‡å¯¼æˆ–éªŒè¯çš„æƒ…å†µã€‚

æŸ¥çœ‹ä¸‹é¢çš„ä»£ç ç‰‡æ®µä»¥å›é¡¾æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­åˆ›å»ºçš„å›¾å½¢ã€‚

**å®Œæ•´ä»£ç **

```python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-haiku-20240307")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.set_entry_point("chatbot")
graph = graph_builder.compile(checkpointer=memory)
```



## ç¬¬å››éƒ¨åˆ†ï¼šäººç±»å‚ä¸

ä»£ç†å¯èƒ½ä¸å¯é ï¼Œå¯èƒ½éœ€è¦äººç±»è¾“å…¥æ‰èƒ½æˆåŠŸå®Œæˆä»»åŠ¡ã€‚åŒæ ·ï¼Œå¯¹äºæŸäº›æ“ä½œï¼Œæ‚¨å¯èƒ½å¸Œæœ›åœ¨è¿è¡Œä¹‹å‰éœ€è¦äººç±»æ‰¹å‡†ï¼Œä»¥ç¡®ä¿ä¸€åˆ‡æŒ‰é¢„æœŸè¿è¡Œã€‚

LangGraphä»¥å¤šç§æ–¹å¼æ”¯æŒ`human-in-the-loop`å·¥ä½œæµã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨==LangGraphçš„`interrupt_before`åŠŸèƒ½==æ¥å§‹ç»ˆä¸­æ–­å·¥å…·èŠ‚ç‚¹ã€‚

é¦–å…ˆï¼Œä»æˆ‘ä»¬ç°æœ‰çš„ä»£ç å¼€å§‹ã€‚ä»¥ä¸‹å†…å®¹ä»ç¬¬ä¸‰éƒ¨åˆ†å¤åˆ¶ã€‚

```python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition

memory = SqliteSaver.from_conn_string(":memory:")


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-haiku-20240307")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
```

```python
/Users/wfh/code/lc/langchain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The method `ChatAnthropic.bind_tools` is in beta. It is actively being worked on, so the API may change.
  warn_beta(
```

ç°åœ¨ï¼Œç¼–è¯‘å›¾å½¢ï¼ŒæŒ‡å®šåœ¨`action`èŠ‚ç‚¹ä¹‹å‰ä¸­æ–­ã€‚

```python
graph = graph_builder.compile(
    checkpointer=memory,
    # è¿™æ˜¯æ–°çš„ï¼
    interrupt_before=["tools"],
    # æ³¨æ„ï¼šå¦‚æœéœ€è¦ï¼Œä¹Ÿå¯ä»¥åœ¨åŠ¨ä½œä¹‹åä¸­æ–­ã€‚
    # interrupt_after=["tools"]
)
```

```python
user_input = "I'm learning LangGraph. Could you do some research on it for me?"
config = {"configurable": {"thread_id": "1"}}
# configæ˜¯stream()æˆ–invoke()çš„**ç¬¬äºŒä¸ªä½ç½®å‚æ•°**ï¼
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

```python
================================ Human Message =================================

I'm learning LangGraph. Could you do some research on it for me?
================================== Ai Message ==================================

[{'text': "Okay, let's do some research on LangGraph:", 'type': 'text'}, {'id': 'toolu_01Be7aRgMEv9cg6ezaFjiCry', 'input': {'query': 'LangGraph'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]
Tool Calls:
  tavily_search_results_json (toolu_01Be7aRgMEv9cg6ezaFjiCry)
 Call ID: toolu_01Be7aRgMEv9cg6ezaFjiCry
  Args:
    query: LangGraph
```

è®©æˆ‘ä»¬æ£€æŸ¥å›¾å½¢çŠ¶æ€ä»¥ç¡®è®¤å…¶å·¥ä½œã€‚

```python
snapshot = graph.get_state(config)
snapshot.next
```

è¾“å‡ºç»“æœï¼š

```python
('action',)
```

**æ³¨æ„** ä¸ä¸Šæ¬¡ä¸åŒï¼Œ"next"èŠ‚ç‚¹è®¾ç½®ä¸º**'action'**ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œä¸­æ–­äº†ï¼è®©æˆ‘ä»¬æ£€æŸ¥å·¥å…·è°ƒç”¨ã€‚

```python
existing_message = snapshot.values["messages"][-1]
existing_message.tool_calls
```

è¾“å‡ºç»“æœï¼š

```python
[{'name': 'tavily_search_results_json',
  'args': {'query': 'LangGraph'},
  'id': 'toolu_01Be7aRgMEv9cg6ezaFjiCry'}]
```

è¿™ä¸ªæŸ¥è¯¢çœ‹èµ·æ¥åˆç†ã€‚æ²¡æœ‰éœ€è¦è¿‡æ»¤çš„å†…å®¹ã€‚äººç±»å¯ä»¥åšçš„æœ€ç®€å•çš„äº‹æƒ…å°±æ˜¯è®©å›¾å½¢ç»§ç»­æ‰§è¡Œã€‚è®©æˆ‘ä»¬æ¥åšè¿™ä¸ªã€‚

æ¥ä¸‹æ¥ï¼Œç»§ç»­å›¾å½¢ï¼ä¼ é€’`None`å°†ä½¿å›¾å½¢ä»ä¸­æ–­çš„åœ°æ–¹ç»§ç»­ï¼Œè€Œä¸ä¼šå‘çŠ¶æ€æ·»åŠ ä»»ä½•æ–°å†…å®¹ã€‚

```python
# `None`å°†ä¸ä¼šå‘å½“å‰çŠ¶æ€æ·»åŠ æ–°å†…å®¹ï¼Œè®©å…¶ç»§ç»­æ‰§è¡Œï¼Œä»¿ä½›ä»æœªä¸­æ–­è¿‡
events = graph.stream(None, config, stream_mode="values")
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

```python
================================= Tool Message =================================
Name: tavily_search_results_json

[{"url": "https://github.com/langchain-ai/langgraph", "content": "LangGraph is a Python package that extends LangChain Expression Language with the ability to coordinate multiple chains across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam and can be used for agent-like behaviors, such as chatbots, with LLMs."}, {"url": "https://langchain-ai.github.io/langgraph//", "content": "LangGraph is a library for building stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain . It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam ."}]
================================== Ai Message ==================================

Based on the search results, LangGraph seems to be a Python library that extends the LangChain library to enable more complex, multi-step interactions with large language models (LLMs). Some key points:

- LangGraph allows coordinating multiple "chains" (or actors) over multiple steps of computation, in a cyclic manner. This enables more advanced agent-like behaviors like chatbots.
- It is inspired by distributed graph processing frameworks like Pregel and Apache Beam.
- LangGraph is built on top of the LangChain library, which provides a framework for building applications with LLMs.

So in summary, LangGraph appears to be a powerful tool for building more sophisticated applications and agents using large language models, by allowing you to coordinate multiple steps and actors in a flexible, graph-like manner. It extends the capabilities of the base LangChain library.

Let me know if you need any clarification or have additional questions!
```

æŸ¥çœ‹æ­¤è°ƒç”¨çš„[LangSmith trace](https://smith.langchain.com/public/6a9012c0-bfa2-4fba-8dce-961d233f9512/r)ä»¥äº†è§£ä¸Šè¿°è°ƒç”¨ä¸­å®Œæˆçš„ç¡®åˆ‡å·¥ä½œã€‚æ³¨æ„ï¼ŒçŠ¶æ€åœ¨ç¬¬ä¸€æ­¥åŠ è½½ï¼Œä»¥ä¾¿æ‚¨çš„èŠå¤©æœºå™¨äººå¯ä»¥ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­ã€‚

**æ­å–œï¼** æ‚¨å·²ä½¿ç”¨`interrupt`ä¸ºèŠå¤©æœºå™¨äººæ·»åŠ äº†äººç±»å‚ä¸æ‰§è¡Œï¼Œä½¿å…¶åœ¨éœ€è¦æ—¶å¯ä»¥è¿›è¡Œäººç±»ç›‘ç£å’Œå¹²é¢„ã€‚è¿™ä¸ºæ‚¨çš„AIç³»ç»Ÿåˆ›å»ºæ½œåœ¨çš„ç”¨æˆ·ç•Œé¢å¼€è¾Ÿäº†å¯èƒ½æ€§ã€‚ç”±äºæˆ‘ä»¬å·²ç»æ·»åŠ äº†**æ£€æŸ¥ç‚¹**ï¼Œå›¾å½¢å¯ä»¥**æ— é™æœŸåœ°**æš‚åœï¼Œå¹¶åœ¨ä»»ä½•æ—¶å€™æ¢å¤ï¼Œå°±åƒä»€ä¹ˆéƒ½æ²¡æœ‰å‘ç”Ÿä¸€æ ·ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ¢ç´¢å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰çŠ¶æ€æ›´æ–°è¿›ä¸€æ­¥è‡ªå®šä¹‰æœºå™¨äººçš„è¡Œä¸ºã€‚

ä»¥ä¸‹æ˜¯æœ¬èŠ‚ä¸­ä½¿ç”¨çš„ä»£ç å‰¯æœ¬ã€‚ä¸ä¹‹å‰çš„éƒ¨åˆ†å”¯ä¸€çš„åŒºåˆ«æ˜¯æ·»åŠ äº†`interrupt_before`å‚æ•°ã€‚

**å®Œæ•´ä»£ç **

```python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode

class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-haiku-20240307")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.set_entry_point("chatbot")

memory = SqliteSaver.from_conn_string(":memory:")
graph = graph_builder.compile(
    checkpointer=memory,
    # è¿™æ˜¯æ–°çš„ï¼
    interrupt_before=["tools"],
    # æ³¨æ„ï¼šå¦‚æœéœ€è¦ï¼Œä¹Ÿå¯ä»¥åœ¨åŠ¨ä½œä¹‹åä¸­æ–­ã€‚
    # interrupt_after=["tools"]
)

```



## ç¬¬äº”éƒ¨åˆ†ï¼šæ‰‹åŠ¨æ›´æ–°çŠ¶æ€

åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ä¸­æ–­å›¾å½¢ï¼Œä»¥ä¾¿äººç±»å¯ä»¥æ£€æŸ¥å…¶æ“ä½œã€‚è¿™è®©äººç±»å¯ä»¥`è¯»å–`çŠ¶æ€ï¼Œä½†å¦‚æœä»–ä»¬æƒ³æ”¹å˜ä»£ç†çš„è·¯çº¿ï¼Œä»–ä»¬éœ€è¦æ‹¥æœ‰`å†™å…¥`è®¿é—®æƒé™ã€‚

å¹¸è¿çš„æ˜¯ï¼ŒLangGraphå…è®¸æ‚¨**æ‰‹åŠ¨æ›´æ–°çŠ¶æ€**ï¼æ›´æ–°çŠ¶æ€å¯ä»¥é€šè¿‡ä¿®æ”¹å…¶æ“ä½œæ¥æ§åˆ¶ä»£ç†çš„è½¨è¿¹ï¼ˆç”šè‡³å¯ä»¥ä¿®æ”¹è¿‡å»ï¼ï¼‰ã€‚è¿™ç§èƒ½åŠ›ç‰¹åˆ«æœ‰ç”¨ï¼Œå½“æ‚¨æƒ³çº æ­£ä»£ç†çš„é”™è¯¯ã€æ¢ç´¢æ›¿ä»£è·¯å¾„æˆ–å¼•å¯¼ä»£ç†æœç‰¹å®šç›®æ ‡å‰è¿›æ—¶ã€‚

æˆ‘ä»¬å°†åœ¨ä¸‹é¢å±•ç¤ºå¦‚ä½•æ›´æ–°æ£€æŸ¥ç‚¹çŠ¶æ€ã€‚é¦–å…ˆï¼Œå®šä¹‰æ‚¨çš„å›¾å½¢ã€‚æˆ‘ä»¬å°†é‡ç”¨ä¹‹å‰çš„å›¾å½¢ã€‚

```python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition


class State(TypedDict):
    messages: Annotated[list, add_messages]


graph_builder = StateGraph(State)


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-haiku-20240307")
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=[tool])
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
memory = SqliteSaver.from_conn_string(":memory:")
graph = graph_builder.compile(
    checkpointer=memory,
    # è¿™æ˜¯æ–°çš„ï¼
    interrupt_before=["tools"],
    # æ³¨æ„ï¼šå¦‚æœéœ€è¦ï¼Œä¹Ÿå¯ä»¥åœ¨æ“ä½œä¹‹åä¸­æ–­ã€‚
    # interrupt_after=["tools"]
)

user_input = "I'm learning LangGraph. Could you do some research on it for me?"
config = {"configurable": {"thread_id": "1"}}
# configæ˜¯stream()æˆ–invoke()çš„**ç¬¬äºŒä¸ªä½ç½®å‚æ•°**ï¼
events = graph.stream({"messages": [("user", user_input)]}, config)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

```python
/Users/wfh/code/lc/langchain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The method `ChatAnthropic.bind_tools` is in beta. It is actively being worked on, so the API may change.
  warn_beta(
```

```python
snapshot = graph.get_state(config)
existing_message = snapshot.values["messages"][-1]
existing_message.pretty_print()
```

```python
================================== Ai Message ==================================

[{'id': 'toolu_01DTyDpJ1kKdNps5yxv3AGJd', 'input': {'query': 'LangGraph'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]
Tool Calls:
  tavily_search_results_json (toolu_01DTyDpJ1kKdNps5yxv3AGJd)
 Call ID: toolu_01DTyDpJ1kKdNps5yxv3AGJd
  Args:
    query: LangGraph
```

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæ‰€æœ‰è¿™äº›éƒ½æ˜¯ä¸Šä¸€èŠ‚çš„*ç²¾ç¡®é‡å¤*ã€‚LLMåˆšåˆšè¯·æ±‚ä½¿ç”¨æœç´¢å¼•æ“å·¥å…·ï¼Œæˆ‘ä»¬çš„å›¾å½¢è¢«ä¸­æ–­äº†ã€‚å¦‚æœæˆ‘ä»¬åƒä»¥å‰ä¸€æ ·ç»§ç»­ï¼Œå·¥å…·å°†è¢«è°ƒç”¨ä»¥æœç´¢ç½‘ç»œã€‚

ä½†å¦‚æœç”¨æˆ·æƒ³è¦å¹²é¢„å‘¢ï¼Ÿå¦‚æœæˆ‘ä»¬è®¤ä¸ºèŠå¤©æœºå™¨äººä¸éœ€è¦ä½¿ç”¨å·¥å…·å‘¢ï¼Ÿ

è®©æˆ‘ä»¬ç›´æ¥æä¾›æ­£ç¡®çš„å“åº”ï¼

```python
from langchain_core.messages import AIMessage

answer = (
    "LangGraph is a library for building stateful, multi-actor applications with LLMs."
)
new_messages = [
    # LLM APIæœŸæœ›æŸäº›ToolMessageä¸å…¶å·¥å…·è°ƒç”¨åŒ¹é…ã€‚æˆ‘ä»¬å°†åœ¨è¿™é‡Œæ»¡è¶³è¿™ä¸€ç‚¹ã€‚
    ToolMessage(content=answer, tool_call_id=existing_message.tool_calls[0]["id"]),
    # ç„¶åç›´æ¥"å°†è¯æ”¾åˆ°LLMçš„å˜´é‡Œ"ï¼Œé€šè¿‡å¡«å……å…¶å“åº”ã€‚
    AIMessage(content=answer),
]

new_messages[-1].pretty_print()
graph.update_state(
    # æ›´æ–°å“ªä¸ªçŠ¶æ€
    config,
    # æä¾›æ›´æ–°çš„å€¼ã€‚æˆ‘ä»¬`State`ä¸­çš„æ¶ˆæ¯æ˜¯â€œä»…è¿½åŠ â€çš„ï¼Œè¿™æ„å‘³ç€è¿™å°†è¿½åŠ åˆ°ç°æœ‰çŠ¶æ€ä¸­ã€‚
    # æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚å›é¡¾å¦‚ä½•æ›´æ–°ç°æœ‰æ¶ˆæ¯ï¼
    {"messages": new_messages},
)

print("\n\nLast 2 messages;")
print(graph.get_state(config).values["messages"][-2:])
```

```python
================================== Ai Message ==================================

LangGraph is a library for building stateful, multi-actor applications with LLMs.


Last 2 messages;
[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='14589ef1-15db-4a75-82a6-d57c40a216d0', tool_call_id='toolu_01DTyDpJ1kKdNps5yxv3AGJd'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='1c657bfb-7690-44c7-a26d-d0d22453013d')]
```

ç°åœ¨å›¾å½¢å·²ç»å®Œæˆï¼Œå› ä¸ºæˆ‘ä»¬æä¾›äº†æœ€ç»ˆçš„å“åº”æ¶ˆæ¯ï¼ç”±äºçŠ¶æ€æ›´æ–°æ¨¡æ‹Ÿäº†å›¾å½¢æ­¥éª¤ï¼Œå®ƒä»¬ç”šè‡³ç”Ÿæˆç›¸åº”çš„è¿½è¸ªã€‚æŸ¥çœ‹ä¸Šè¿°`update_state`è°ƒç”¨çš„[LangSmith trace](https://smith.langchain.com/public/c45207bb-bd26-4c9a-b631-928bbeebfbcb/r)ï¼Œäº†è§£å…·ä½“æƒ…å†µã€‚

**æ³¨æ„** æˆ‘ä»¬çš„æ–°æ¶ˆæ¯è¢«*è¿½åŠ *åˆ°çŠ¶æ€ä¸­å·²ç»å­˜åœ¨çš„æ¶ˆæ¯ä¸­ã€‚è®°å¾—æˆ‘ä»¬æ˜¯å¦‚ä½•å®šä¹‰`State`ç±»å‹çš„å—ï¼Ÿ

```python
class State(TypedDict):
    messages: Annotated[list, add_messages]
```

æˆ‘ä»¬ç”¨é¢„æ„å»ºçš„`add_messages`å‡½æ•°å¯¹`messages`è¿›è¡Œäº†æ³¨é‡Šã€‚è¿™æŒ‡ç¤ºå›¾å½¢å§‹ç»ˆå°†å€¼è¿½åŠ åˆ°ç°æœ‰åˆ—è¡¨ä¸­ï¼Œè€Œä¸æ˜¯ç›´æ¥è¦†ç›–åˆ—è¡¨ã€‚åŒæ ·çš„é€»è¾‘ä¹Ÿé€‚ç”¨äºè¿™é‡Œï¼Œæ‰€ä»¥æˆ‘ä»¬ä¼ é€’ç»™`update_state`çš„æ¶ˆæ¯è¢«ä»¥ç›¸åŒçš„æ–¹å¼è¿½åŠ äº†ï¼

`update_state`å‡½æ•°çš„æ“ä½œå°±åƒæ‚¨çš„å›¾å½¢ä¸­çš„ä¸€ä¸ªèŠ‚ç‚¹ä¸€æ ·ï¼é»˜è®¤æƒ…å†µä¸‹ï¼Œæ›´æ–°æ“ä½œä½¿ç”¨æœ€åæ‰§è¡Œçš„èŠ‚ç‚¹ï¼Œä½†æ‚¨å¯ä»¥åœ¨ä¸‹é¢æ‰‹åŠ¨æŒ‡å®šå®ƒã€‚è®©æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªæ›´æ–°ï¼Œå¹¶å‘Šè¯‰å›¾å½¢å°†å…¶è§†ä¸ºæ¥è‡ª"chatbot"çš„æ›´æ–°ã€‚

```python
graph.update_state(
    config,
    {"messages": [AIMessage(content="I'm an AI expert!")]},
    # è¿™ä¸ªå‡½æ•°ä½œä¸ºå“ªä¸ªèŠ‚ç‚¹æ“ä½œã€‚å®ƒå°†è‡ªåŠ¨ç»§ç»­å¤„ç†ï¼Œå°±åƒè¿™ä¸ªèŠ‚ç‚¹åˆšåˆšè¿è¡Œè¿‡ä¸€æ ·ã€‚
    as_node="chatbot",
)
```

```python
{'configurable': {'thread_id': '1',
  'thread_ts': '2024-05-06T22:27:57.350721+00:00'}}
```

æŸ¥çœ‹æ­¤æ›´æ–°è°ƒç”¨çš„[LangSmith trace](https://smith.langchain.com/public/ce83989f-6e49-4bdd-bcd5-f54ca55c8d00/r/30b1406a-ae5b-4e9e-9fe5-032be6efb92e)äº†è§£è¯¦ç»†ä¿¡æ¯ã€‚**æ³¨æ„** ä»è¿½è¸ªä¸­å¯ä»¥çœ‹å‡ºï¼Œå›¾å½¢ç»§ç»­è¿›å…¥`tools_condition`è¾¹ç¼˜ã€‚æˆ‘ä»¬åˆšåˆšå‘Šè¯‰å›¾å½¢å°†æ›´æ–°`as_node="chatbot"`ã€‚å¦‚æœæˆ‘ä»¬ä»å›¾è¡¨å¼€å§‹å¹¶ä»`chatbot`èŠ‚ç‚¹å¼€å§‹ï¼Œæˆ‘ä»¬è‡ªç„¶ä¼šè¿›å…¥`tools_condition`è¾¹ç¼˜ï¼Œç„¶å`__end__`ï¼Œå› ä¸ºæˆ‘ä»¬çš„æ›´æ–°æ¶ˆæ¯ä¸åŒ…å«å·¥å…·è°ƒç”¨ã€‚

```python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # è¿™éœ€è¦ä¸€äº›é¢å¤–çš„ä¾èµ–é¡¹ï¼Œæ˜¯å¯é€‰çš„
    pass
```

![image-20240707211111464](./../assets/image-20240707211111464.png)

åƒä»¥å‰ä¸€æ ·æ£€æŸ¥å½“å‰çŠ¶æ€ï¼Œä»¥ç¡®è®¤æ£€æŸ¥ç‚¹åæ˜ äº†æˆ‘ä»¬çš„æ‰‹åŠ¨æ›´æ–°ã€‚

```python
snapshot = graph.get_state(config)
print(snapshot.values["messages"][-3:])
print(snapshot.next)
```

```python
[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='14589ef1-15db-4a75-82a6-d57c40a216d0', tool_call_id='toolu_01DTyDpJ1kKdNps5yxv3AGJd'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='1c657bfb-7690-44c7-a26d-d0d22453013d'), AIMessage(content="I'm an AI expert!", id='acd668e3-ba31-42c0-843c-00d0994d5885')]
()
```

**æ³¨æ„** æˆ‘ä»¬ç»§ç»­å°†AIæ¶ˆæ¯æ·»åŠ åˆ°çŠ¶æ€ä¸­ã€‚ç”±äºæˆ‘ä»¬ä½œä¸º`chatbot`æ“ä½œï¼Œå¹¶ä¸”å“åº”äº†ä¸åŒ…å«`tool_calls`çš„AIæ¶ˆæ¯ï¼Œå›¾å½¢çŸ¥é“å®ƒå·²è¿›å…¥å®ŒæˆçŠ¶æ€ï¼ˆ`next`ä¸ºç©ºï¼‰ã€‚

**å¦‚æœä½ æƒ³è¦†ç›–ç°æœ‰æ¶ˆæ¯æ€ä¹ˆåŠï¼Ÿ**

æˆ‘ä»¬ç”¨æ¥æ³¨é‡Šå›¾å½¢`State`çš„[`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages)å‡½æ•°æ§åˆ¶äº†å¦‚ä½•å¯¹`messages`é”®è¿›è¡Œæ›´æ–°ã€‚æ­¤å‡½æ•°ä¼šæŸ¥çœ‹æ–°`messages`åˆ—è¡¨ä¸­çš„ä»»ä½•æ¶ˆæ¯IDã€‚å¦‚æœIDä¸ç°æœ‰çŠ¶æ€ä¸­çš„æ¶ˆæ¯åŒ¹é…ï¼Œ[`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages)å°†ä½¿ç”¨æ–°å†…å®¹è¦†ç›–ç°æœ‰æ¶ˆæ¯ã€‚

ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬æ›´æ–°å·¥å…·è°ƒç”¨ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬ä»æœç´¢å¼•æ“è·å¾—è‰¯å¥½çš„ç»“æœï¼é¦–å…ˆï¼Œå¯åŠ¨ä¸€ä¸ªæ–°çº¿ç¨‹ï¼š

```python
user_input = "I'm learning LangGraph. Could you do some research on it for me?"
config = {"configurable": {"thread_id": "2"}}  # æˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨thread_id = 2
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

```python
================================ Human Message =================================

I'm learning LangGraph. Could you do some research on it for me?
================================== Ai Message ==================================

[{'id': 'toolu_013MvjoDHnv476ZGzyPFZhrR', 'input': {'query': 'LangGraph'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]
Tool Calls:
  tavily_search_results_json (toolu_013MvjoDHnv476ZGzyPFZhrR)
 Call ID: toolu_013MvjoDHnv476ZGzyPFZhrR
  Args:
    query: LangGraph
```

**æ¥ä¸‹æ¥ï¼Œ** è®©æˆ‘ä»¬æ›´æ–°ä»£ç†çš„å·¥å…·è°ƒç”¨ã€‚ä¹Ÿè®¸æˆ‘ä»¬æƒ³ç‰¹åˆ«æœç´¢äººç±»å‚ä¸çš„å·¥ä½œæµã€‚

```python
from langchain_core.messages import AIMessage

snapshot = graph.get_state(config)
existing_message = snapshot.values["messages"][-1]
print("Original")
print("Message ID", existing_message.id)
print(existing_message.tool_calls[0])
new_tool_call = existing_message.tool_calls[0].copy()
new_tool_call["args"]["query"] = "LangGraph human-in-the-loop workflow"
new_message = AIMessage(
    content=existing_message.content,
    tool_calls=[new_tool_call],
    # é‡è¦ï¼IDæ˜¯LangGraphçŸ¥é“è¦†ç›–çŠ¶æ€ä¸­çš„æ¶ˆæ¯è€Œä¸æ˜¯è¿½åŠ æ­¤æ¶ˆæ¯çš„æ–¹æ³•
    id=existing_message.id,
)

print("Updated")
print(new_message.tool_calls[0])
print("Message ID", new_message.id)
graph.update_state(config, {"messages": [new_message]})

print("\n\nTool calls")
graph.get_state(config).values["messages"][-1].tool_calls
```

```python
Original
Message ID run-59283969-1076-45fe-bee8-ebfccab163c3-0
{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, 'id': 'toolu_013MvjoDHnv476ZGzyPFZhrR'}
Updated
{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph human-in-the-loop workflow'}, 'id': 'toolu_013MvjoDHnv476ZGzyPFZhrR'}
Message ID run-59283969-1076-45fe-bee8-ebfccab163c3-0


Tool calls
```

è¾“å‡ºç»“æœï¼š

```python
[{'name': 'tavily_search_results_json',
  'args': {'query': 'LangGraph human-in-the-loop workflow'},
  'id': 'toolu_013MvjoDHnv476ZGzyPFZhrR'}]
```

**æ³¨æ„** æˆ‘ä»¬ä¿®æ”¹äº†AIçš„å·¥å…·è°ƒç”¨ï¼Œä»¥æœç´¢"LangGraph human-in-the-loop workflow"è€Œä¸æ˜¯ç®€å•çš„"LangGraph"ã€‚

æŸ¥çœ‹çŠ¶æ€æ›´æ–°è°ƒç”¨çš„[LangSmith trace](https://smith.langchain.com/public/cd7c09a6-758d-41d4-8de1-64ab838b2338/r)ï¼Œå¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ–°æ¶ˆæ¯æˆåŠŸæ›´æ–°äº†ä¹‹å‰çš„AIæ¶ˆæ¯ã€‚

é€šè¿‡ä¼ é€’`None`å’Œç°æœ‰é…ç½®æ¥æ¢å¤å›¾å½¢ã€‚

```python
events = graph.stream(None, config, stream_mode="values")
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

```python
================================= Tool Message =================================
Name: tavily_search_results_json

[{"url": "https://langchain-ai.github.io/langgraph/how-tos/human-in-the-loop/", "content": "Human-in-the-loop\u00b6 When creating LangGraph agents, it is often nice to add a human in the loop component. This can be helpful when giving them access to tools. ... from langgraph.graph import MessageGraph, END # Define a new graph workflow = MessageGraph # Define the two nodes we will cycle between workflow. add_node (\"agent\", call_model) ..."}, {"url": "https://langchain-ai.github.io/langgraph/how-tos/chat_agent_executor_with_function_calling/human-in-the-loop/", "content": "Human-in-the-loop. In this example we will build a ReAct Agent that has a human in the loop. We will use the human to approve specific actions. This examples builds off the base chat executor. It is highly recommended you learn about that executor before going through this notebook. You can find documentation for that example here."}]
================================== Ai Message ==================================

Based on the search results, LangGraph appears to be a framework for building AI agents that can interact with humans in a conversational way. The key points I gathered are:

- LangGraph allows for "human-in-the-loop" workflows, where a human can be involved in approving or reviewing actions taken by the AI agent.
- This can be useful for giving the AI agent access to various tools and capabilities, with the human able to provide oversight and guidance.
- The framework includes components like "MessageGraph" for defining the conversational flow between the agent and human.

Overall, LangGraph seems to be a way to create conversational AI agents that can leverage human input and guidance, rather than operating in a fully autonomous way. Let me know if you need any clarification or have additional questions!
```

æŸ¥çœ‹å·¥å…·è°ƒç”¨å’Œç¨åLLMå“åº”çš„[trace](https://smith.langchain.com/public/2d633326-14ad-4248-a391-2757d01851c4/r/6464f2f2-edb4-4ef3-8f48-ee4e249f2ad0)ã€‚**æ³¨æ„** ç°åœ¨å›¾å½¢ä½¿ç”¨æˆ‘ä»¬æ›´æ–°çš„æŸ¥è¯¢è¯è°ƒç”¨æœç´¢å¼•æ“â€”â€”æˆ‘ä»¬èƒ½å¤Ÿæ‰‹åŠ¨è¦†ç›–LLMçš„æœç´¢ï¼

æ‰€æœ‰è¿™äº›éƒ½åæ˜ åœ¨å›¾å½¢çš„æ£€æŸ¥ç‚¹è®°å¿†ä¸­ï¼Œè¿™æ„å‘³ç€å¦‚æœæˆ‘ä»¬ç»§ç»­å¯¹è¯ï¼Œå®ƒå°†è®°ä½æ‰€æœ‰*ä¿®æ”¹è¿‡çš„*çŠ¶æ€ã€‚

```python
events = graph.stream(
    {
        "messages": (
            "user",
            "Remember what I'm learning about?",
        )
    },
    config,
    stream_mode="values",
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

```python
================================ Human Message =================================

Remember what I'm learning about?
================================== Ai Message ==================================

Ah yes, now I remember - you mentioned earlier that you are learning about LangGraph.

LangGraph is the framework I researched in my previous response, which is for building conversational AI agents that can incorporate human input and oversight.

So based on our earlier discussion, it seems you are currently learning about and exploring the LangGraph system for creating human-in-the-loop AI agents. Please let me know if I have the right understanding now.
```

**æ­å–œï¼** æ‚¨å·²ä½¿ç”¨`interrupt_before`å’Œ`update_state`ä½œä¸ºäººç±»å‚ä¸å·¥ä½œæµçš„ä¸€éƒ¨åˆ†ï¼Œæ‰‹åŠ¨ä¿®æ”¹äº†çŠ¶æ€ã€‚ä¸­æ–­å’ŒçŠ¶æ€ä¿®æ”¹å…è®¸æ‚¨æ§åˆ¶ä»£ç†çš„è¡Œä¸ºã€‚ç»“åˆæŒä¹…æ£€æŸ¥ç‚¹ï¼Œè¿™æ„å‘³ç€æ‚¨å¯ä»¥`æš‚åœ`ä¸€ä¸ªæ“ä½œï¼Œå¹¶åœ¨ä»»ä½•æ—¶å€™`æ¢å¤`ã€‚å½“å›¾å½¢ä¸­æ–­æ—¶ï¼Œç”¨æˆ·ä¸å¿…åœ¨çº¿ï¼

æœ¬èŠ‚çš„å›¾å½¢ä»£ç ä¸å‰å‡ èŠ‚ç›¸åŒã€‚éœ€è¦è®°ä½çš„å…³é”®ä»£ç ç‰‡æ®µæ˜¯æ·»åŠ `.compile(..., interrupt_before=[...])`ï¼ˆæˆ–`interrupt_after`ï¼‰ï¼Œå¦‚æœæ‚¨å¸Œæœ›åœ¨å›¾å½¢åˆ°è¾¾æŸä¸ªèŠ‚ç‚¹æ—¶æ˜¾å¼æš‚åœå®ƒã€‚ç„¶åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`update_state`æ¥ä¿®æ”¹æ£€æŸ¥ç‚¹ï¼Œå¹¶æ§åˆ¶å›¾å½¢åº”è¯¥å¦‚ä½•è¿›è¡Œã€‚



## ç¬¬å…­éƒ¨åˆ†ï¼šè‡ªå®šä¹‰çŠ¶æ€

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¾èµ–äº†ä¸€ä¸ªç®€å•çš„çŠ¶æ€ï¼ˆå®ƒåªæ˜¯ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨ï¼ï¼‰ã€‚ä½¿ç”¨è¿™ä¸ªç®€å•çš„çŠ¶æ€æ‚¨å¯ä»¥èµ°å¾—å¾ˆè¿œï¼Œä½†å¦‚æœæ‚¨æƒ³å®šä¹‰å¤æ‚çš„è¡Œä¸ºè€Œä¸ä¾èµ–æ¶ˆæ¯åˆ—è¡¨ï¼Œå¯ä»¥åœ¨çŠ¶æ€ä¸­æ·»åŠ å…¶ä»–å­—æ®µã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡æ·»åŠ ä¸€ä¸ªæ–°èŠ‚ç‚¹æ¥æ‰©å±•æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººï¼Œä»¥è¯´æ˜è¿™ä¸€ç‚¹ã€‚

åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ç¡®å®šæ€§åœ°æ¶‰åŠäº†ä¸€ä¸ªäººç±»ï¼šæ¯å½“è°ƒç”¨å·¥å…·æ—¶ï¼Œå›¾å½¢**æ€»æ˜¯**ä¼šä¸­æ–­ã€‚å‡è®¾æˆ‘ä»¬å¸Œæœ›èŠå¤©æœºå™¨äººèƒ½å¤Ÿé€‰æ‹©æ˜¯å¦ä¾èµ–äººç±»ã€‚

ä¸€ç§æ–¹æ³•æ˜¯åˆ›å»ºä¸€ä¸ªé€šè¿‡â€œäººç±»â€èŠ‚ç‚¹ï¼Œå›¾å½¢å°†åœ¨æ­¤èŠ‚ç‚¹ä¹‹å‰æ€»æ˜¯åœæ­¢ã€‚æˆ‘ä»¬åªæœ‰åœ¨LLMè°ƒç”¨â€œäººç±»â€å·¥å…·æ—¶æ‰æ‰§è¡Œæ­¤èŠ‚ç‚¹ã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬å°†åœ¨å›¾å½¢çŠ¶æ€ä¸­åŒ…æ‹¬ä¸€ä¸ªâ€œask_humanâ€æ ‡å¿—ï¼Œå¦‚æœLLMè°ƒç”¨æ­¤å·¥å…·ï¼Œæˆ‘ä»¬å°†ç¿»è½¬æ­¤æ ‡å¿—ã€‚

ä¸‹é¢ï¼Œå®šä¹‰è¿™ä¸ªæ–°çš„å›¾å½¢ï¼Œå¹¶æ›´æ–°`State`ã€‚

```python
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict

from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition


class State(TypedDict):
    messages: Annotated[list, add_messages]
    # è¿™ä¸ªæ ‡å¿—æ˜¯æ–°çš„
    ask_human: bool
```

æ¥ä¸‹æ¥ï¼Œå®šä¹‰ä¸€ä¸ªæ¨¡å¼ä»¥å‘æ¨¡å‹æ˜¾ç¤ºï¼Œä»¥ä¾¿å®ƒå†³å®šæ˜¯å¦è¯·æ±‚å¸®åŠ©ã€‚

```python
from langchain_core.pydantic_v1 import BaseModel


class RequestAssistance(BaseModel):
    """å°†å¯¹è¯å‡çº§åˆ°ä¸“å®¶ã€‚å¦‚æœæ‚¨æ— æ³•ç›´æ¥æä¾›å¸®åŠ©æˆ–ç”¨æˆ·éœ€è¦è¶…å‡ºæ‚¨æƒé™çš„æ”¯æŒï¼Œè¯·ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚

    è¦ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œè¯·ä¼ é€’ç”¨æˆ·çš„â€œè¯·æ±‚â€ï¼Œä»¥ä¾¿ä¸“å®¶æä¾›æ­£ç¡®çš„æŒ‡å¯¼ã€‚
    """

    request: str
```

æ¥ä¸‹æ¥ï¼Œå®šä¹‰èŠå¤©æœºå™¨äººèŠ‚ç‚¹ã€‚è¿™é‡Œçš„ä¸»è¦ä¿®æ”¹æ˜¯å¦‚æœæˆ‘ä»¬çœ‹åˆ°èŠå¤©æœºå™¨äººè°ƒç”¨äº†`RequestAssistance`å·¥å…·ï¼Œåˆ™ç¿»è½¬`ask_human`æ ‡å¿—ã€‚

```python
tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-haiku-20240307")
# æˆ‘ä»¬å¯ä»¥å°†llmç»‘å®šåˆ°å·¥å…·å®šä¹‰ã€pydanticæ¨¡å‹æˆ–jsonæ¨¡å¼
llm_with_tools = llm.bind_tools(tools + [RequestAssistance])


def chatbot(state: State):
    response = llm_with_tools.invoke(state["messages"])
    ask_human = False
    if (
        response.tool_calls
        and response.tool_calls[0]["name"] == RequestAssistance.__name__
    ):
        ask_human = True
    return {"messages": [response], "ask_human": ask_human}
```

```python
/Users/wfh/code/lc/langchain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The method `ChatAnthropic.bind_tools` is in beta. It is actively being worked on, so the API may change.
  warn_beta(
```

æ¥ä¸‹æ¥ï¼Œåˆ›å»ºå›¾å½¢æ„å»ºå™¨å¹¶å°†èŠå¤©æœºå™¨äººå’Œå·¥å…·èŠ‚ç‚¹æ·»åŠ åˆ°å›¾å½¢ä¸­ï¼Œä¸ä¹‹å‰ç›¸åŒã€‚

```python
graph_builder = StateGraph(State)

graph_builder.add_node("chatbot", chatbot)
graph_builder.add_node("tools", ToolNode(tools=[tool]))
```

æ¥ä¸‹æ¥ï¼Œåˆ›å»ºâ€œäººç±»â€èŠ‚ç‚¹ã€‚æ­¤èŠ‚ç‚¹å‡½æ•°ä¸»è¦æ˜¯æˆ‘ä»¬å›¾å½¢ä¸­çš„å ä½ç¬¦ï¼Œå°†è§¦å‘ä¸­æ–­ã€‚å¦‚æœäººç±»**æ²¡æœ‰**åœ¨ä¸­æ–­æœŸé—´æ‰‹åŠ¨æ›´æ–°çŠ¶æ€ï¼Œå®ƒä¼šæ’å…¥ä¸€ä¸ªå·¥å…·æ¶ˆæ¯ï¼Œä»¥ä¾¿LLMçŸ¥é“è¯·æ±‚äº†ç”¨æˆ·ä½†æ²¡æœ‰å“åº”ã€‚æ­¤èŠ‚ç‚¹è¿˜ä¼šå–æ¶ˆè®¾ç½®`ask_human`æ ‡å¿—ï¼Œä»¥ä¾¿å›¾å½¢çŸ¥é“é™¤éè¿›ä¸€æ­¥è¯·æ±‚ï¼Œå¦åˆ™ä¸ä¼šé‡æ–°è®¿é—®è¯¥èŠ‚ç‚¹ã€‚

```python
from langchain_core.messages import AIMessage, ToolMessage


def create_response(response: str, ai_message: AIMessage):
    return ToolMessage(
        content=response,
        tool_call_id=ai_message.tool_calls[0]["id"],
    )


def human_node(state: State):
    new_messages = []
    if not isinstance(state["messages"][-1], ToolMessage):
        # é€šå¸¸æƒ…å†µä¸‹ï¼Œç”¨æˆ·ä¼šåœ¨ä¸­æ–­æœŸé—´æ›´æ–°çŠ¶æ€ã€‚
        # å¦‚æœä»–ä»¬é€‰æ‹©ä¸è¿™æ ·åšï¼Œæˆ‘ä»¬å°†åŒ…å«ä¸€ä¸ªå ä½ç¬¦ToolMessageä»¥
        # è®©LLMç»§ç»­ã€‚
        new_messages.append(
            create_response("No response from human.", state["messages"][-1])
        )
    return {
        # è¿½åŠ æ–°æ¶ˆæ¯
        "messages": new_messages,
        # å–æ¶ˆè®¾ç½®æ ‡å¿—
        "ask_human": False,
    }


graph_builder.add_node("human", human_node)
```

æ¥ä¸‹æ¥ï¼Œå®šä¹‰æ¡ä»¶é€»è¾‘ã€‚å¦‚æœè®¾ç½®äº†æ ‡å¿—ï¼Œ`select_next_node`å°†è·¯ç”±åˆ°`human`èŠ‚ç‚¹ã€‚å¦åˆ™ï¼Œå®ƒå°†è®©é¢„æ„å»ºçš„`tools_condition`å‡½æ•°é€‰æ‹©ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚

å›æƒ³ä¸€ä¸‹ï¼Œ`tools_condition`å‡½æ•°åªæ˜¯æ£€æŸ¥`chatbot`æ˜¯å¦åœ¨å…¶å“åº”æ¶ˆæ¯ä¸­åŒ…å«ä»»ä½•`tool_calls`ã€‚å¦‚æœæ˜¯ï¼Œå®ƒä¼šè·¯ç”±åˆ°`action`èŠ‚ç‚¹ã€‚å¦åˆ™ï¼Œå®ƒç»“æŸå›¾å½¢ã€‚

```python
def select_next_node(state: State):
    if state["ask_human"]:
        return "human"
    # å¦åˆ™ï¼Œæˆ‘ä»¬å¯ä»¥åƒä»¥å‰ä¸€æ ·è·¯ç”±
    return tools_condition(state)


graph_builder.add_conditional_edges(
    "chatbot",
    select_next_node,
    {"human": "human", "tools": "tools", "__end__": "__end__"},
)
```

æœ€åï¼Œæ·»åŠ ç®€å•çš„æœ‰å‘è¾¹å¹¶ç¼–è¯‘å›¾å½¢ã€‚è¿™äº›è¾¹æŒ‡ç¤ºå›¾å½¢æ¯æ¬¡æ‰§è¡Œå®Œæˆæ—¶**æ€»æ˜¯**ä»èŠ‚ç‚¹`a`->`b`æµåŠ¨ã€‚

```python
# å…¶ä½™çš„ä¿æŒä¸å˜
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge("human", "chatbot")
graph_builder.add_edge(START, "chatbot")
memory = SqliteSaver.from_conn_string(":memory:")
graph = graph_builder.compile(
    checkpointer=memory,
    # æˆ‘ä»¬åœ¨è¿™é‡Œä¸­æ–­'human'ä¹‹å‰ã€‚
    interrupt_before=["human"],
)
```

å¦‚æœæ‚¨å®‰è£…äº†å¯è§†åŒ–ä¾èµ–é¡¹ï¼Œå¯ä»¥åœ¨ä¸‹é¢æŸ¥çœ‹å›¾å½¢ç»“æ„ï¼š

```python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # è¿™éœ€è¦ä¸€äº›é¢å¤–çš„ä¾èµ–é¡¹ï¼Œæ˜¯å¯é€‰çš„
    pass
```

![image-20240707211145129](./../assets/image-20240707211145129.png)

èŠå¤©æœºå™¨äººå¯ä»¥è¯·æ±‚äººç±»å¸®åŠ©ï¼ˆchatbot->select->humanï¼‰ã€è°ƒç”¨æœç´¢å¼•æ“å·¥å…·ï¼ˆchatbot->select->actionï¼‰æˆ–ç›´æ¥å“åº”ï¼ˆchatbot->select->**end**ï¼‰ã€‚ä¸€æ—¦æ‰§è¡Œäº†æŸä¸ªåŠ¨ä½œæˆ–è¯·æ±‚ï¼Œå›¾å½¢å°†è¿‡æ¸¡å›`chatbot`èŠ‚ç‚¹ä»¥ç»§ç»­æ“ä½œã€‚

è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªå›¾å½¢çš„å®é™…æ“ä½œã€‚æˆ‘ä»¬å°†è¯·æ±‚ä¸“å®¶å¸®åŠ©ä»¥è¯´æ˜æˆ‘ä»¬çš„å›¾å½¢ã€‚

```python
user_input = "I need some expert guidance for building this AI agent. Could you request assistance for me?"
config = {"configurable": {"thread_id": "1"}}
# configæ˜¯stream()æˆ–invoke()çš„**ç¬¬äºŒä¸ªä½ç½®å‚æ•°**ï¼
events = graph.stream(
    {"messages": [("user", user_input)]}, config, stream_mode="values"
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

```python
================================ Human Message =================================

I need some expert guidance for building this AI agent. Could you request assistance for me?
================================== Ai Message ==================================

[{'id': 'toolu_017XaQuVsoAyfXeTfDyv55Pc', 'input': {'request': 'I need some expert guidance for building this AI agent.'}, 'name': 'RequestAssistance', 'type': 'tool_use'}]
Tool Calls:
  RequestAssistance (toolu_017XaQuVsoAyfXeTfDyv55Pc)
 Call ID: toolu_017XaQuVsoAyfXeTfDyv55Pc
  Args:
    request: I need some expert guidance for building this AI agent.
```

**æ³¨æ„ï¼š** LLMè°ƒç”¨äº†æˆ‘ä»¬æä¾›çš„"`RequestAssistance`"å·¥å…·ï¼Œå¹¶è®¾ç½®äº†ä¸­æ–­ã€‚è®©æˆ‘ä»¬æ£€æŸ¥å›¾å½¢çŠ¶æ€ä»¥ç¡®è®¤ã€‚

```python
snapshot = graph.get_state(config)
snapshot.next
```

è¾“å‡ºç»“æœï¼š

```python
('human',)
```

å›¾å½¢çŠ¶æ€ç¡®å®åœ¨`'human'`èŠ‚ç‚¹ä¹‹å‰**ä¸­æ–­**ã€‚åœ¨æ­¤åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å……å½“â€œä¸“å®¶â€ï¼Œå¹¶é€šè¿‡æ·»åŠ æ–°å·¥å…·æ¶ˆæ¯æ‰‹åŠ¨æ›´æ–°çŠ¶æ€ã€‚

æ¥ä¸‹æ¥ï¼Œé€šè¿‡ä»¥ä¸‹æ­¥éª¤å“åº”èŠå¤©æœºå™¨äººçš„è¯·æ±‚ï¼š

1. åˆ›å»ºä¸€ä¸ª`ToolMessage`ï¼Œå¹¶å°†æˆ‘ä»¬çš„å“åº”ä¼ é€’å›èŠå¤©æœºå™¨äººã€‚
2. è°ƒç”¨`update_state`æ‰‹åŠ¨æ›´æ–°å›¾å½¢çŠ¶æ€ã€‚

```python
ai_message = snapshot.values["messages"][-1]
human_response = (
    "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent."
    " It's much more reliable and extensible than simple autonomous agents."
)
tool_message = create_response(human_response, ai_message)
graph.update_state(config, {"messages": [tool_message]})
```

è¾“å‡ºç»“æœï¼š

```python
{'configurable': {'thread_id': '1',
  'thread_ts': '2024-05-06T22:31:39.973

392+00:00'}}
```

æ‚¨å¯ä»¥æ£€æŸ¥çŠ¶æ€ä»¥ç¡®è®¤æˆ‘ä»¬çš„å“åº”å·²æ·»åŠ ã€‚

```python
graph.get_state(config).values["messages"]
```

è¾“å‡ºç»“æœï¼š

```python
[HumanMessage(content='I need some expert guidance for building this AI agent. Could you request assistance for me?', id='ab75eb9d-cce7-4e44-8de7-b0b375a86972'),
 AIMessage(content=[{'id': 'toolu_017XaQuVsoAyfXeTfDyv55Pc', 'input': {'request': 'I need some expert guidance for building this AI agent.'}, 'name': 'RequestAssistance', 'type': 'tool_use'}], response_metadata={'id': 'msg_0199PiK6kmVAbeo1qmephKDq', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 486, 'output_tokens': 63}}, id='run-ff07f108-5055-4343-8910-2fa40ead3fb9-0', tool_calls=[{'name': 'RequestAssistance', 'args': {'request': 'I need some expert guidance for building this AI agent.'}, 'id': 'toolu_017XaQuVsoAyfXeTfDyv55Pc'}]),
 ToolMessage(content="We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.", id='19f2eb9f-a742-46aa-9047-60909c30e64a', tool_call_id='toolu_017XaQuVsoAyfXeTfDyv55Pc')]
```

æ¥ä¸‹æ¥ï¼Œé€šè¿‡ä½¿ç”¨`None`ä½œä¸ºè¾“å…¥æ¥**æ¢å¤**å›¾å½¢ã€‚

```python
events = graph.stream(None, config, stream_mode="values")
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

```python
================================= Tool Message =================================

We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.
================================== Ai Message ==================================

It looks like the experts have provided some guidance on how to build your AI agent. They suggested checking out LangGraph, which they say is more reliable and extensible than simple autonomous agents. Please let me know if you need any other assistance - I'm happy to help coordinate with the expert team further.
```

**æ³¨æ„** èŠå¤©æœºå™¨äººå·²ç»åœ¨å…¶æœ€ç»ˆå“åº”ä¸­åˆå¹¶äº†æ›´æ–°çš„çŠ¶æ€ã€‚ç”±äº**ä¸€åˆ‡**éƒ½è¢«æ£€æŸ¥ç‚¹ä¿å­˜ï¼Œå¾ªç¯ä¸­çš„â€œä¸“å®¶â€å¯ä»¥åœ¨ä»»ä½•æ—¶å€™æ‰§è¡Œæ›´æ–°ï¼Œè€Œä¸å½±å“å›¾å½¢çš„æ‰§è¡Œã€‚

**æ­å–œï¼** æ‚¨ç°åœ¨å·²ç»å‘åŠ©æ‰‹å›¾å½¢æ·»åŠ äº†ä¸€ä¸ªé¢å¤–çš„èŠ‚ç‚¹ï¼Œè®©èŠå¤©æœºå™¨äººè‡ªè¡Œå†³å®šæ˜¯å¦éœ€è¦ä¸­æ–­æ‰§è¡Œã€‚æ‚¨é€šè¿‡åœ¨å›¾å½¢`State`ä¸­æ·»åŠ ä¸€ä¸ªæ–°å­—æ®µ`ask_human`å¹¶åœ¨ç¼–è¯‘å›¾å½¢æ—¶ä¿®æ”¹ä¸­æ–­é€»è¾‘æ¥å®ç°è¿™ä¸€ç‚¹ã€‚è¿™è®©æ‚¨å¯ä»¥åŠ¨æ€åœ°å°†äººç±»çº³å…¥å¾ªç¯ï¼ŒåŒæ—¶æ¯æ¬¡æ‰§è¡Œå›¾å½¢æ—¶ä¿æŒå®Œæ•´çš„**è®°å¿†**ã€‚

æˆ‘ä»¬å¿«å®Œæˆæ•™ç¨‹äº†ï¼Œä½†åœ¨ç»“æŸä¹‹å‰è¿˜æœ‰ä¸€ä¸ªæ¦‚å¿µæˆ‘ä»¬æƒ³å›é¡¾ä¸€ä¸‹ï¼Œå®ƒè¿æ¥äº†`æ£€æŸ¥ç‚¹`å’Œ`çŠ¶æ€æ›´æ–°`ã€‚

æœ¬èŠ‚çš„ä»£ç å¦‚ä¸‹ä¾›æ‚¨å‚è€ƒã€‚

**Full Code**

```py
from typing import Annotated

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import BaseMessage
from langchain_core.pydantic_v1 import BaseModel
from typing_extensions import TypedDict

from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition


class State(TypedDict):
    messages: Annotated[list, add_messages]
    # This flag is new
    ask_human: bool


class RequestAssistance(BaseModel):
    """Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.

    To use this function, relay the user's 'request' so the expert can provide the right guidance.
    """

    request: str


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-haiku-20240307")
# We can bind the llm to a tool definition, a pydantic model, or a json schema
llm_with_tools = llm.bind_tools(tools + [RequestAssistance])


def chatbot(state: State):
    response = llm_with_tools.invoke(state["messages"])
    ask_human = False
    if (
        response.tool_calls
        and response.tool_calls[0]["name"] == RequestAssistance.__name__
    ):
        ask_human = True
    return {"messages": [response], "ask_human": ask_human}


graph_builder = StateGraph(State)

graph_builder.add_node("chatbot", chatbot)
graph_builder.add_node("tools", ToolNode(tools=[tool]))


def create_response(response: str, ai_message: AIMessage):
    return ToolMessage(
        content=response,
        tool_call_id=ai_message.tool_calls[0]["id"],
    )


def human_node(state: State):
    new_messages = []
    if not isinstance(state["messages"][-1], ToolMessage):
        # Typically, the user will have updated the state during the interrupt.
        # If they choose not to, we will include a placeholder ToolMessage to
        # let the LLM continue.
        new_messages.append(
            create_response("No response from human.", state["messages"][-1])
        )
    return {
        # Append the new messages
        "messages": new_messages,
        # Unset the flag
        "ask_human": False,
    }


graph_builder.add_node("human", human_node)


def select_next_node(state: State):
    if state["ask_human"]:
        return "human"
    # Otherwise, we can route as before
    return tools_condition(state)


graph_builder.add_conditional_edges(
    "chatbot",
    select_next_node,
    {"human": "human", "tools": "tools", "__end__": "__end__"},
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge("human", "chatbot")
graph_builder.set_entry_point("chatbot")
memory = SqliteSaver.from_conn_string(":memory:")
graph = graph_builder.compile(
    checkpointer=memory,
    interrupt_before=["human"],
)
```



## ç¬¬ä¸ƒéƒ¨åˆ†ï¼šæ—¶é—´æ—…è¡Œ

åœ¨å…¸å‹çš„èŠå¤©æœºå™¨äººå·¥ä½œæµç¨‹ä¸­ï¼Œç”¨æˆ·ä¸æœºå™¨äººäº¤äº’1æ¬¡æˆ–å¤šæ¬¡ä»¥å®Œæˆä»»åŠ¡ã€‚åœ¨å‰å‡ èŠ‚ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°å¦‚ä½•æ·»åŠ è®°å¿†å’Œäººç±»å‚ä¸ä»¥èƒ½å¤Ÿæ£€æŸ¥æˆ‘ä»¬çš„å›¾å½¢çŠ¶æ€å¹¶æ‰‹åŠ¨è¦†ç›–çŠ¶æ€ä»¥æ§åˆ¶æœªæ¥çš„å“åº”ã€‚

ä½†å¦‚æœæ‚¨å¸Œæœ›ç”¨æˆ·ä»å…ˆå‰çš„å“åº”å¼€å§‹å¹¶â€œåˆ†æ”¯â€ä»¥æ¢ç´¢ä¸åŒçš„ç»“æœæ€ä¹ˆåŠï¼Ÿæˆ–è€…å¦‚æœæ‚¨å¸Œæœ›ç”¨æˆ·èƒ½å¤Ÿâ€œå€’å›â€åŠ©æ‰‹çš„å·¥ä½œä»¥ä¿®å¤ä¸€äº›é”™è¯¯æˆ–å°è¯•ä¸åŒçš„ç­–ç•¥ï¼ˆåœ¨è‡ªåŠ¨åŒ–è½¯ä»¶å·¥ç¨‹å¸ˆç­‰åº”ç”¨ä¸­å¾ˆå¸¸è§ï¼‰æ€ä¹ˆåŠï¼Ÿ

æ‚¨å¯ä»¥ä½¿ç”¨LangGraphçš„å†…ç½®â€œæ—¶é—´æ—…è¡Œâ€åŠŸèƒ½åˆ›å»ºè¿™äº›ä½“éªŒå’Œæ›´å¤šä½“éªŒã€‚

åœ¨æœ¬èŠ‚ä¸­ï¼Œæ‚¨å°†é€šè¿‡ä½¿ç”¨å›¾å½¢çš„`get_state_history`æ–¹æ³•è·å–æ£€æŸ¥ç‚¹æ¥â€œå€’å›â€æ‚¨çš„å›¾å½¢ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥åœ¨è¿™ä¸ªå…ˆå‰çš„æ—¶é—´ç‚¹æ¢å¤æ‰§è¡Œã€‚

é¦–å…ˆï¼Œå›å¿†æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººå›¾å½¢ã€‚æˆ‘ä»¬ä¸éœ€è¦è¿›è¡Œ**ä»»ä½•**æ›´æ”¹ï¼š

```python
from typing import Annotated, Literal

from langchain_anthropic import ChatAnthropic
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import AIMessage, BaseMessage, ToolMessage
from langchain_core.pydantic_v1 import BaseModel
from typing_extensions import TypedDict

from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition


class State(TypedDict):
    messages: Annotated[list, add_messages]
    # è¿™ä¸ªæ ‡å¿—æ˜¯æ–°çš„
    ask_human: bool


class RequestAssistance(BaseModel):
    """å°†å¯¹è¯å‡çº§åˆ°ä¸“å®¶ã€‚å¦‚æœæ‚¨æ— æ³•ç›´æ¥æä¾›å¸®åŠ©æˆ–ç”¨æˆ·éœ€è¦è¶…å‡ºæ‚¨æƒé™çš„æ”¯æŒï¼Œè¯·ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚

    è¦ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œè¯·ä¼ é€’ç”¨æˆ·çš„â€œè¯·æ±‚â€ï¼Œä»¥ä¾¿ä¸“å®¶æä¾›æ­£ç¡®çš„æŒ‡å¯¼ã€‚
    """

    request: str


tool = TavilySearchResults(max_results=2)
tools = [tool]
llm = ChatAnthropic(model="claude-3-haiku-20240307")
# æˆ‘ä»¬å¯ä»¥å°†llmç»‘å®šåˆ°å·¥å…·å®šä¹‰ã€pydanticæ¨¡å‹æˆ–jsonæ¨¡å¼
llm_with_tools = llm.bind_tools(tools + [RequestAssistance])


def chatbot(state: State):
    response = llm_with_tools.invoke(state["messages"])
    ask_human = False
    if (
        response.tool_calls
        and response.tool_calls[0]["name"] == RequestAssistance.__name__
    ):
        ask_human = True
    return {"messages": [response], "ask_human": ask_human}


graph_builder = StateGraph(State)

graph_builder.add_node("chatbot", chatbot)
graph_builder.add_node("tools", ToolNode(tools=[tool]))


def create_response(response: str, ai_message: AIMessage):
    return ToolMessage(
        content=response,
        tool_call_id=ai_message.tool_calls[0]["id"],
    )


def human_node(state: State):
    new_messages = []
    if not isinstance(state["messages"][-1], ToolMessage):
        # é€šå¸¸æƒ…å†µä¸‹ï¼Œç”¨æˆ·ä¼šåœ¨ä¸­æ–­æœŸé—´æ›´æ–°çŠ¶æ€ã€‚
        # å¦‚æœä»–ä»¬é€‰æ‹©ä¸è¿™æ ·åšï¼Œæˆ‘ä»¬å°†åŒ…å«ä¸€ä¸ªå ä½ç¬¦ToolMessageä»¥
        # è®©LLMç»§ç»­ã€‚
        new_messages.append(
            create_response("No response from human.", state["messages"][-1])
        )
    return {
        # è¿½åŠ æ–°æ¶ˆæ¯
        "messages": new_messages,
        # å–æ¶ˆè®¾ç½®æ ‡å¿—
        "ask_human": False,
    }


graph_builder.add_node("human", human_node)


def select_next_node(state: State) -> Literal["human", "tools", "__end__"]:
    if state["ask_human"]:
        return "human"
    # å¦åˆ™ï¼Œæˆ‘ä»¬å¯ä»¥åƒä»¥å‰ä¸€æ ·è·¯ç”±
    return tools_condition(state)


graph_builder.add_conditional_edges(
    "chatbot",
    select_next_node,
    {"human": "human", "tools": "tools", "__end__": "__end__"},
)
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge("human", "chatbot")
graph_builder.add_edge(START, "chatbot")
memory = SqliteSaver.from_conn_string(":memory:")
graph = graph_builder.compile(
    checkpointer=memory,
    interrupt_before=["human"],
)
```

```python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # è¿™éœ€è¦ä¸€äº›é¢å¤–çš„ä¾èµ–é¡¹ï¼Œæ˜¯å¯é€‰çš„
    pass
```

è®©æˆ‘ä»¬çš„å›¾å½¢æ‰§è¡Œå‡ æ­¥ã€‚æ¯ä¸€æ­¥éƒ½ä¼šåœ¨å…¶çŠ¶æ€å†å²ä¸­æ£€æŸ¥ç‚¹ï¼š

```python
config = {"configurable": {"thread_id": "1"}}
events = graph.stream(
    {
        "messages": [
            ("user", "I'm learning LangGraph. Could you do some research on it for me?")
        ]
    },
    config,
    stream_mode="values",
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

```python
================================ Human Message =================================

I'm learning LangGraph. Could you do some research on it for me?
================================== Ai Message ==================================

[{'text': "Okay, let me look into LangGraph for you. Here's what I found:", 'type': 'text'}, {'id': 'toolu_011AQ2FT4RupVka2LVMV3Gci', 'input': {'query': 'LangGraph'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]
Tool Calls:
  tavily_search_results_json (toolu_011AQ2FT4RupVka2LVMV3Gci)
 Call ID: toolu_011AQ2FT4RupVka2LVMV3Gci
  Args:
    query: LangGraph
================================= Tool Message =================================
Name: tavily_search_results_json

[{"url": "https://langchain-ai.github.io/langgraph/", "content": "LangGraph is framework agnostic (each node is a regular python function). It extends the core Runnable API (shared interface for streaming, async, and batch calls) to make it easy to: Seamless state management across multiple turns of conversation or tool usage. The ability to flexibly route between nodes based on dynamic criteria."}, {"url": "https://blog.langchain.dev/langgraph-multi-agent-workflows/", "content": "As a part of the launch, we highlighted two simple runtimes: one that is the equivalent of the AgentExecutor in langchain, and a second that was a version of that aimed at message passing and chat models.\n It's important to note that these three examples are only a few of the possible examples we could highlight - there are almost assuredly other examples out there and we look forward to seeing what the community comes up with!\n LangGraph: Multi-Agent Workflows\nLinks\nLast week we highlighted LangGraph - a new package (available in both Python and JS) to better enable creation of LLM workflows containing cycles, which are a critical component of most agent runtimes. \"\nAnother key difference between Autogen and LangGraph is that LangGraph is fully integrated into the LangChain ecosystem, meaning you take fully advantage of all the LangChain integrations and LangSmith observability.\n As part of this launch, we're also excited to highlight a few applications built on top of LangGraph that utilize the concept of multiple agents.\n"}]
================================== Ai Message ==================================

Based on the search results, here's what I've learned about LangGraph:

- LangGraph is a framework-agnostic tool that extends the Runnable API to make it easier to manage state and routing between different nodes or agents in a conversational workflow. 

- It's part of the LangChain ecosystem, so it integrates with other LangChain tools and observability features.

- LangGraph enables the creation of multi-agent workflows, where you can have different "nodes" or agents that can communicate and pass information to each other.

- This allows for more complex conversational flows and the ability to chain together different capabilities, tools, or models.

- The key benefits seem to be around state management, flexible routing between agents, and the ability to create more sophisticated and dynamic conversational workflows.

Let me know if you need any clarification or have additional questions! I'm happy to do more research on LangGraph if you need further details.
```

```python
events = graph.stream(
    {
        "messages": [
            ("user", "Ya that's helpful. Maybe I'll build an autonomous agent with it!")
        ]
    },
    config,
    stream_mode="values",
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

```python
================================ Human Message =================================

Ya that's helpful. Maybe I'll build an autonomous agent with it!
================================== Ai Message ==================================

[{'text': "That's great that you're interested in building an autonomous agent using LangGraph! Here are a few additional thoughts on how you could approach that:", 'type': 'text'}, {'id': 'toolu_01L3V9FhZG5Qx9jqRGfWGtS2', 'input': {'query': 'building autonomous agents with langgraph'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]
Tool Calls:
  tavily_search_results_json (toolu_01L3V9FhZG5Qx9jqRGfWGtS2)
 Call ID: toolu_01L3V9FhZG5Qx9jqRGfWGtS2
  Args:
    query: building autonomous

 agents with langgraph
================================= Tool Message =================================
Name: tavily_search_results_json

[{"url": "https://github.com/langchain-ai/langgraphjs", "content": "LangGraph is a library for building stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain.js.It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam.The current interface exposed is one inspired by ..."}, {"url": "https://github.com/langchain-ai/langgraph", "content": "LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam.The current interface exposed is one inspired by NetworkX.. The main use is for adding cycles to your LLM ..."}]
================================== Ai Message ==================================

The key things to keep in mind:

1. LangGraph is designed to help coordinate multiple "agents" or "actors" that can pass information back and forth. This allows you to build more complex, multi-step workflows.

2. You'll likely want to define different nodes or agents that handle specific tasks or capabilities. LangGraph makes it easy to route between these agents based on the state of the conversation.

3. Make sure to leverage the LangChain ecosystem - things like prompts, memory, agents, tools etc. LangGraph integrates with these to give you a powerful set of building blocks.

4. Pay close attention to state management - LangGraph helps you manage state across multiple interactions, which is crucial for an autonomous agent.

5. Consider how you'll handle things like user intent, context, and goal-driven behavior. LangGraph gives you the flexibility to implement these kinds of complex behaviors.

Let me know if you have any other specific questions as you start prototyping your autonomous agent! I'm happy to provide more guidance.
```

ç°åœ¨æˆ‘ä»¬å·²ç»è®©ä»£ç†æ‰§è¡Œäº†å‡ æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥`é‡æ”¾`å®Œæ•´çš„çŠ¶æ€å†å²ï¼ŒæŸ¥çœ‹å‘ç”Ÿçš„æ‰€æœ‰äº‹æƒ…ã€‚

```python
to_replay = None
for state in graph.get_state_history(config):
    print("Num Messages: ", len(state.values["messages"]), "Next: ", state.next)
    print("-" * 80)
    if len(state.values["messages"]) == 6:
        # æˆ‘ä»¬æœ‰ç‚¹ä»»æ„åœ°é€‰æ‹©äº†ä¸€ä¸ªç‰¹å®šçŠ¶æ€ï¼ŒåŸºäºçŠ¶æ€ä¸­çš„èŠå¤©æ¶ˆæ¯æ•°é‡ã€‚
        to_replay = state
```

```python
Num Messages:  8 Next:  ()
--------------------------------------------------------------------------------
Num Messages:  7 Next:  ('chatbot',)
--------------------------------------------------------------------------------
Num Messages:  6 Next:  ('action',)
--------------------------------------------------------------------------------
Num Messages:  5 Next:  ('chatbot',)
--------------------------------------------------------------------------------
Num Messages:  4 Next:  ()
--------------------------------------------------------------------------------
Num Messages:  3 Next:  ('chatbot',)
--------------------------------------------------------------------------------
Num Messages:  2 Next:  ('action',)
--------------------------------------------------------------------------------
Num Messages:  1 Next:  ('chatbot',)
--------------------------------------------------------------------------------
```

**æ³¨æ„** æ¯ä¸€æ­¥çš„æ£€æŸ¥ç‚¹éƒ½ä¿å­˜äº†å›¾å½¢çš„çŠ¶æ€ã€‚è¿™**è·¨è¶Šäº†è°ƒç”¨**ï¼Œå› æ­¤æ‚¨å¯ä»¥åœ¨æ•´ä¸ªçº¿ç¨‹çš„å†å²è®°å½•ä¸­å€’å›ã€‚æˆ‘ä»¬é€‰æ‹©äº†`to_replay`ä½œä¸ºè¦æ¢å¤çš„çŠ¶æ€ã€‚è¿™æ˜¯ç¬¬äºŒä¸ªå›¾å½¢è°ƒç”¨ä¸­`chatbot`èŠ‚ç‚¹ä¹‹åçš„çŠ¶æ€ã€‚

ä»è¿™ä¸€ç‚¹æ¢å¤åº”è¯¥ä¼šè°ƒç”¨**action**èŠ‚ç‚¹ã€‚

```python
print(to_replay.next)
print(to_replay.config)
```

```python
('action',)
{'configurable': {'thread_id': '1', 'thread_ts': '2024-05-06T22:33:10.211424+00:00'}}
```

**æ³¨æ„** æ£€æŸ¥ç‚¹çš„é…ç½®ï¼ˆ`to_replay.config`ï¼‰åŒ…å«äº†ä¸€ä¸ª`thread_ts` **æ—¶é—´æˆ³**ã€‚æä¾›æ­¤`thread_ts`å€¼å‘Šè¯‰LangGraphçš„æ£€æŸ¥å™¨**åŠ è½½**æ¥è‡ªé‚£ä¸ªæ—¶é—´ç‚¹çš„çŠ¶æ€ã€‚è®©æˆ‘ä»¬è¯•è¯•ï¼š

```python
# `to_replay.config`ä¸­çš„`thread_ts`å¯¹åº”äºæˆ‘ä»¬å·²ä¿å­˜åˆ°æ£€æŸ¥ç‚¹çš„çŠ¶æ€ã€‚
for event in graph.stream(None, to_replay.config, stream_mode="values"):
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

```python
================================= Tool Message =================================
Name: tavily_search_results_json

[{"url": "https://valentinaalto.medium.com/getting-started-with-langgraph-66388e023754", "content": "Sign up\nSign in\nSign up\nSign in\nMember-only story\nGetting Started with LangGraph\nBuilding multi-agents application with graph frameworks\nValentina Alto\nFollow\n--\nShare\nOver the last year, LangChain has established itself as one of the most popular AI framework available in the market. This new library, introduced in January\u2026\n--\n--\nWritten by Valentina Alto\nData&AI Specialist at @Microsoft | MSc in Data Science | AI, Machine Learning and Running enthusiast\nHelp\nStatus\nAbout\nCareers\nBlog\nPrivacy\nTerms\nText to speech\nTeams Since the concept of multi-agent applications \u2014 the ones exhibiting different agents, each having a specific personality and tools to access \u2014 is getting real and mainstream (see the rise of libraries projects like AutoGen), LangChain\u2019s developers introduced a new library to make it easier to manage these kind of agentic applications. Nevertheless, those chains were lacking the capability of introducing cycles into their runtime, meaning that there is no out-of-the-box framework to enable the LLM to reason over the next best action in a kind of for-loop scenario. The main feature of LangChain \u2014 as the name suggests \u2014 is its ability to easily create the so-called chains."}, {"url": "https://blog.langchain.dev/langgraph-multi-agent-workflows/", "content": "As a part of the launch, we highlighted two simple runtimes: one that is the equivalent of the AgentExecutor in langchain, and a second that was a version of that aimed at message passing and chat models.\n It's important to note that these three examples are only a few of the possible examples we could highlight - there are almost assuredly other examples out there and we look forward to seeing what the community comes up with!\n LangGraph: Multi-Agent Workflows\nLinks\nLast week we highlighted LangGraph - a new package (available in both Python and JS) to better enable creation of LLM workflows containing cycles, which are a critical component of most agent runtimes. \"\nAnother key difference between Autogen and LangGraph is that LangGraph is fully integrated into the LangChain ecosystem, meaning you take fully advantage of all the LangChain integrations and LangSmith observability.\n As part of this launch, we're also excited to highlight a few applications built on top of LangGraph that utilize the concept of multiple agents.\n"}]
================================== Ai Message ==================================

The key things I gathered are:

- LangGraph is well-suited for building multi-agent applications, where you have different agents with their own capabilities, tools, and personality.

- It allows you to create more complex workflows with cycles and feedback loops, which is critical for building autonomous agents that can reason about their next best actions.

- The integration with LangChain means you can leverage other useful features like state management, observability, and integrations with various language models and data sources.

Some tips for building an autonomous agent with LangGraph:

1. Define the different agents/nodes in your workflow and their specific responsibilities/capabilities.
2. Set up the connections and routing between the agents so they can pass information and decisions back and forth.
3. Implement logic within each agent to assess the current state and determine the optimal next action.
4. Use LangChain features like memory and toolkits to give your agents access to relevant information and abilities.
5. Monitor the overall system behavior and iteratively improve the agent interactions and decision-making.

Let me know if you have any other questions! I'm happy to provide more guidance as you start building your autonomous agent with LangGraph.
```

æ³¨æ„ï¼Œå›¾å½¢ä»**action**èŠ‚ç‚¹æ¢å¤æ‰§è¡Œã€‚æ‚¨å¯ä»¥é€šè¿‡ä¸Šé¢æ‰“å°çš„ç¬¬ä¸€ä¸ªå€¼æ˜¯æˆ‘ä»¬æœç´¢å¼•æ“å·¥å…·çš„å“åº”æ¥ç¡®å®šè¿™ä¸€ç‚¹ã€‚

**æ­å–œï¼** æ‚¨ç°åœ¨ä½¿ç”¨äº†LangGraphä¸­çš„æ—¶é—´æ—…è¡Œæ£€æŸ¥ç‚¹éå†ã€‚èƒ½å¤Ÿå€’å›å¹¶æ¢ç´¢ä¸åŒçš„è·¯å¾„ä¸ºè°ƒè¯•ã€å®éªŒå’Œäº¤äº’å¼åº”ç”¨ç¨‹åºæ‰“å¼€äº†æ— é™å¯èƒ½ã€‚

## ç»“è®º

æ­å–œï¼æ‚¨å·²ç»å®Œæˆäº†å…¥é—¨æ•™ç¨‹ï¼Œå¹¶åœ¨LangGraphä¸­æ„å»ºäº†ä¸€ä¸ªæ”¯æŒå·¥å…·è°ƒç”¨ã€æŒä¹…è®°å¿†ã€äººç±»å‚ä¸äº¤äº’ç”šè‡³æ—¶é—´æ—…è¡Œçš„èŠå¤©æœºå™¨äººï¼

[LangGraphæ–‡æ¡£](https://langchain-ai.github.io/langgraph/)æ˜¯æ·±å…¥äº†è§£åº“åŠŸèƒ½çš„å¥½èµ„æºã€‚